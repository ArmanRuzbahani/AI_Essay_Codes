{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0164b08",
   "metadata": {},
   "source": [
    "# ๐ง ุขุดูุง ุจุง ูพุฑุฏุงุฒุด ุฒุจุงู ุทุจุน (Natural Language Processing - NLP)\n",
    "\n",
    "**ูพุฑุฏุงุฒุด ุฒุจุงู ุทุจุน (NLP)** ฺฉ ุงุฒ ุดุงุฎูโูุง ููู **ููุด ูุตููุน ๐ค** ุงุณุช ฺฉู ุจู ุชุนุงูู ู ุงุฑุชุจุงุท ฺฉุงููพูุชุฑ ุจุง ุฒุจุงู ุงูุณุงูโูุง ๐ฃ๏ธ ูโูพุฑุฏุงุฒุฏ. ุฏุฑ ูุงูุน NLP ุณุน ุฏุงุฑุฏ ุจู ฺฉุงููพูุชุฑูุง ฺฉูฺฉ ฺฉูุฏ ุชุง ุฒุจุงู ุทุจุน ุงูุณุงูโูุง ุฑุง ุจููููุฏุ ุชูุณุฑ ฺฉููุฏ ู ุจู ุขู ูพุงุณุฎ ุฏููุฏ.\n",
    "\n",
    "---\n",
    "\n",
    "## ๐ฏ ุงูุฏุงู ุงุตู NLP\n",
    "- ๐งพ ุฏุฑฺฉ ูุนู ู ููููู ูุชู\n",
    "- ๐ ุงุณุชุฎุฑุงุฌ ุงุทูุงุนุงุช ููู ุงุฒ ูุชู\n",
    "- ๐ ุชุฑุฌูู ุฒุจุงูโูุง ุจู ฺฉุฏฺฏุฑ\n",
    "- ๐ ุชุดุฎุต ู ุทุจููโุจูุฏ ุงุญุณุงุณุงุช\n",
    "- โ๏ธ ุฎูุงุตูโุณุงุฒ ูุชูู ุทููุงู\n",
    "- ๐ ุชููุฏ ูุชู ู ฺฏูุชุงุฑ ุจู ุฒุจุงู ุทุจุน\n",
    "\n",
    "---\n",
    "\n",
    "## ๐ผ ฺฉุงุฑุจุฑุฏูุง ุฑุงุฌ NLP\n",
    "- ๐ **ูุชุฑุฌูโูุง ุขููุงู:** ูุงููุฏ Google Translate\n",
    "- ๐๏ธ **ุฏุณุชุงุฑูุง ุตูุช ููุดููุฏ:** ูุงููุฏ Siriุ Alexa ู Google Assistant\n",
    "- ๐ฌ **ุณุณุชูโูุง ุชุญูู ุงุญุณุงุณุงุช:** ุชุญูู ูุธุฑุงุช ฺฉุงุฑุจุฑุงู ุฏุฑ ุดุจฺฉูโูุง ุงุฌุชูุงุน\n",
    "- ๐ค **ุฑุจุงุชโูุง ฺุช (Chatbots):** ูพุงุณุฎโฺฏู ุฎูุฏฺฉุงุฑ ุจู ฺฉุงุฑุจุฑุงู\n",
    "- ๐ฏ **ุณุณุชูโูุง ูพุดููุงุฏุฏููุฏู:** ุชูุตู ูููุ ฺฉุชุงุจุ ููุณู ู...\n",
    "- โ๏ธ **ุชุญูู ูุชูโูุง ุญููู ู ูพุฒุดฺฉ:** ุงุณุชุฎุฑุงุฌ ุงุทูุงุนุงุช ฺฉูุฏ ุงุฒ ุงุณูุงุฏ ุชุฎุตุต\n",
    "\n",
    "---\n",
    "\n",
    "## ๐งฐ ุชฺฉูฺฉโูุง ู ุงุจุฒุงุฑูุง ูุนุฑูู ุฏุฑ NLP\n",
    "\n",
    "### ๐งน ูพุดโูพุฑุฏุงุฒุด ูุชู (Text Preprocessing)\n",
    "- ุญุฐู ููุฒ ๐งฝ\n",
    "- ุฑุดูโุงุจ ฺฉููุงุช (Stemming) ๐ฑ\n",
    "- ุฑุดูโุงุจ ูุนูุง (Lemmatization) ๐\n",
    "- ุญุฐู ฺฉููุงุช ุชููู (Stop Words) ๐\n",
    "\n",
    "### ๐ง ุจุฑุฏุงุฑูุง ุฌุงุณุงุฒ ฺฉููุงุช (Word Embeddings)\n",
    "- Word2Vec ๐ก  \n",
    "- GloVe ๐งค  \n",
    "- FastText โก\n",
    "\n",
    "### ๐ค ูุฏูโูุง ุงุฏฺฏุฑ ูุงุดู ู ุงุฏฺฏุฑ ุนูู\n",
    "- ๐ ูุฏูโูุง ฺฉูุงุณฺฉ: SVMุ Naive Bayesุ Logistic Regression  \n",
    "- ๐ ูุฏูโูุง ุนูู: RNNุ LSTMุ CNN  \n",
    "- ๐ ูุฏูโูุง ุชุฑูุณููุฑูุฑ: BERTุ GPT ู ุณุงุฑ ูุฏูโูุง HuggingFace\n",
    "\n",
    "---\n",
    "\n",
    "## โ๏ธ ฺุงูุดโูุง NLP\n",
    "- ๐ ุงุจูุงู ู ูพฺุฏฺฏ ุฒุจุงู ุทุจุน  \n",
    "- ๐ค ูุฌูุฏ ูุนุงู ูุฎุชูู ุจุฑุง ฺฉ ฺฉููู (Ambiguity)  \n",
    "- ๐ ุชูุงูุชโูุง ฺฏุฑุงูุฑ ู ูุญู ุฏุฑ ุฒุจุงูโูุง  \n",
    "- ๐ค ุฏุดูุงุฑ ุฏุฑฺฉ ฺฉูุงูุ ุทูุฒ ู ุงุญุณุงุณุงุช ูพููุงู\n",
    "\n",
    "---\n",
    "\n",
    "## ๐ ฺฉุชุงุจุฎุงููโูุง ูุนุฑูู NLP ุฏุฑ ูพุงุชูู\n",
    "- ๐ฆ **NLTK** โ ุงุจุฒุงุฑูุง ูพุงูโุง ุจุฑุง ูพุดโูพุฑุฏุงุฒุด ูุชู  \n",
    "- โก **spaCy** โ ุณุฑุน ู ููุงุณุจ ุจุฑุง ูพุฑูฺูโูุง ูุงูุน  \n",
    "- ๐ค **Transformers (Hugging Face)** โ ูุฏูโูุง ูพุดุฑูุชู BERT ู GPT  \n",
    "- ๐ **Gensim** โ ุจุฑุง ุจุฑุฏุงุฑุณุงุฒ ู ูุฏูโุณุงุฒ ููุถูุนุงุช (Topic Modeling)\n",
    "\n",
    "---\n",
    "\n",
    "> ๐ ุงุฏฺฏุฑ NLP ูพู ุงุณุช ูุงู ุนููู ุงูุณุงู ู ุนููู ฺฉุงููพูุชุฑ! ุชุฑฺฉุจ ุงุฒ ุฒุจุงูุ ุขูุงุฑุ ู ููุด ูุตููุน ุจุฑุง ุฏุฑฺฉ ุจูุชุฑ ุฌูุงู ุงูุณุงู ๐\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519f7a4",
   "metadata": {},
   "source": [
    "## ๐ ูุฏู ูุงุฑฺฉูู ูพููุงู (Hidden Markov Model - HMM) ุฏุฑ ุชุญูู ุงุญุณุงุณุงุช\n",
    "\n",
    "**ูุฏู ูุงุฑฺฉูู ูพููุงู (HMM)** ฺฉ ุงุฒ ูุฏูโูุง ุขูุงุฑ ูพุฑฺฉุงุฑุจุฑุฏ ุฏุฑ ูพุฑุฏุงุฒุด ุฒุจุงู ุทุจุน (NLP) ุงุณุช ฺฉู ูโุชูุงูุฏ ุจูโุตูุฑุช ูุคุซุฑ ุจุฑุง **ุชุญูู ุงุญุณุงุณุงุช (Sentiment Analysis)** ุฏุฑ ูุชูู ุจูโฺฉุงุฑ ุฑูุฏ.\n",
    "\n",
    "### ๐ง ุงุฏูโ ุงุตู HMM\n",
    "HMM ูุฏู ุงุณุช ฺฉู ูุฑุถ ูโฺฉูุฏ:\n",
    "- ุฏุฑ ูพุดุช ุฏุงุฏูโูุง ูุงุจู ูุดุงูุฏู (ูุซูุงู ฺฉููุงุช ฺฉ ุฌููู ๐)ุ ุญุงูุงุช ูพููุงู ูุฌูุฏ ุฏุงุฑูุฏ (ูุซูุงู ุงุญุณุงุณ ููุณูุฏู ๐๐๐ก)\n",
    "- ุงู ุญุงูุชโูุง ูพููุงู ุจูโุตูุฑุช ุฒูุฌุฑูโุง ู ุจุง ูุงุจุณุชฺฏ ุฒูุงู ุธุงูุฑ ูโุดููุฏ ๐\n",
    "- ูุง ููุท ุฎุฑูุฌโูุง ุฑุง ูโุจููุ ูู ุญุงูุชโูุง ุฑุง โ ู ูุฏู ุจุงุฏ ุขูโูุง ุฑุง **ุชุฎูู ุจุฒูุฏ**\n",
    "\n",
    "---\n",
    "\n",
    "### ๐ง ุงุฌุฒุง ูุฏู HMM ุจุฑุง ุชุญูู ุงุญุณุงุณุงุช\n",
    "1. **ุญุงูุชโูุง ูพููุงู (Hidden States):**  \n",
    "   ุงุญุณุงุณุงุช ูุงููุฏ ูุซุจุช ๐ุ ููู ๐ุ ุฎูุซ ๐\n",
    "\n",
    "2. **ุฏุงุฏูโูุง ูุงุจู ูุดุงูุฏู (Observations):**  \n",
    "   ฺฉููุงุช ุง ุฌููุงุช ูุชู ูุซู \"ุนุงู\"ุ \"ุจุฏ\"ุ \"ุจโุชูุงูุช\"\n",
    "\n",
    "3. **ูุงุชุฑุณ ุงูุชูุงู (Transition Probabilities):**  \n",
    "   ุงุญุชูุงู ุชุบุฑ ุงุญุณุงุณ ุฏุฑ ุทูู ุฌูููโูุง ุง ูุชู โ ูุซูุงู ุงุฒ \"ูุซุจุช\" ุจู \"ููู\"\n",
    "\n",
    "4. **ูุงุชุฑุณ ุงูุชุดุงุฑ (Emission Probabilities):**  \n",
    "   ุงุญุชูุงู ุธุงูุฑ ุดุฏู ฺฉ ฺฉููู ุฎุงุต ุฏุฑ ฺฉ ุงุญุณุงุณ ุฎุงุต โ ูุซูุงู ุงุญุชูุงู ุงูฺฉู \"ุนุงู\" ุฏุฑ ุญุงูุช ูุซุจุช ุธุงูุฑ ุดูุฏ\n",
    "\n",
    "5. **ุงุญุชูุงู ุดุฑูุน (Initial Probabilities):**  \n",
    "   ุงุญุชูุงู ุงูฺฉู ูุชู ุจุง ฺู ุงุญุณุงุณ ุดุฑูุน ุดูุฏ\n",
    "\n",
    "---\n",
    "\n",
    "### ๐ก ฺฉุงุฑุจุฑุฏ HMM ุฏุฑ Sentiment Analysis\n",
    "\n",
    "ูุฏู HMM ูโุชูุงูุฏ ุจุฑุง ุชุญูู ุงุญุณุงุณุงุช ุฏุฑ **ูุชูู ุฏูุจุงููโุฏุงุฑ ุง ุฏุงุณุชุงู** ุจุณุงุฑ ููุฏ ุจุงุดุฏ. ุจุฑุฎูุงู ุฑูุดโูุง ุณุงุฏู ฺฉู ูุฑ ุฌููู ุฑุง ุฌุฏุง ุจุฑุฑุณ ูโฺฉููุฏุ HMM ูุงุจุณุชฺฏ ุจู ุฌููุงุช ู ุชุบุฑ ุงุญุณุงุณุงุช ุฏุฑ ุทูู ูุชู ุฑุง ูุฒ ุฏุฑ ูุธุฑ ูโฺฏุฑุฏ.\n",
    "\n",
    "#### โ ูุซุงู:\n",
    "ูุฑุถ ฺฉูุฏ ฺฉ ููุฏ ููู ุจูโุตูุฑุช ุฒุฑ ุงุณุช:\n",
    "> \"ููู ุดุฑูุน ฺฉููุฏ ุฏุงุดุชุ ูู ุจุง ฺฏุฐุดุช ุฒูุงู ุฌุฐุงุจโุชุฑ ุดุฏ. ูพุงุงูโุจูุฏ ูุงูุนุงู ุงุญุณุงุณ ุจูุฏ.\"\n",
    "\n",
    "HMM ูโุชูุงูุฏ ุงูฺฏู ุชุบุฑ ุงุญุณุงุณุงุช ุฑุง ุฏุฑ ุงู ููุฏ ุดูุงุณุง ฺฉูุฏ:\n",
    "- ุงุจุชุฏุง: ููู ๐  \n",
    "- ูุงูู: ุฎูุซ ๐ ุง ุฑู ุจู ูุซุจุช ๐  \n",
    "- ุงูุชูุง: ูุซุจุช ๐\n",
    "\n",
    "---\n",
    "\n",
    "### ๐ ูุฒุงุง ุงุณุชูุงุฏู ุงุฒ HMM ุฏุฑ ุชุญูู ุงุญุณุงุณุงุช:\n",
    "- ูุฏูโุณุงุฒ ุฏูุจุงููโุง ู ุฒูุงู ุงุญุณุงุณุงุช\n",
    "- ุงูฺฉุงู ูพุดโุจู ุงุญุณุงุณ ุฌููู ุจุนุฏ\n",
    "- ุฏุฑฺฉ ุจูุชุฑ ุงุฒ ุชุบุฑุงุช ุงุญุณุงุณ ุฏุฑ ูุชูโูุง ุทููุงู ูุซู ููุฏุ ุฏุงุณุชุงู ุง ฺฏูุชฺฏู\n",
    "\n",
    "---\n",
    "\n",
    "### ๐ ุฌูุนโุจูุฏ\n",
    "ูุฏู ูุงุฑฺฉูู ูพููุงู ุจุง ุณุงุฎุชุงุฑ ุฒูุฌุฑูโุง ุฎูุฏุ ุงุจุฒุงุฑ ูุฏุฑุชููุฏ ุจุฑุง **ุชุญูู ุงุญุณุงุณุงุช ุฏูุจุงููโุฏุงุฑ** ุฏุฑ ูุชูู ุทุจุน ุงุณุช. ุงู ูุฏู ุจูโูฺู ุฒูุงู ฺฉุงุฑุจุฑุฏ ุฏุงุฑุฏ ฺฉู ุชุบุฑุงุช ุงุญุณุงุณ ุฏุฑ ุทูู ูุชู ููู ุจุงุดูุฏ ู ุชุญูู ุฌูููโุง ฺฉุงู ูุจุงุดุฏ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff95f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ููุฏ ฺฉุฑุฏู ูุฏู ุงุฒ Hugging Face\n",
    "model_name = \"HooshvareLab/bert-base-parsbert-sentiment-snappfood\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# ุฌูููโ ูุฑูุฏ ุจุฑุง ุชุญูู ุงุญุณุงุณ\n",
    "text = \"ุงู ููู ูุงูุนุงู ูููโุงูุนุงุฏู ุจูุฏ! ุจุงุฒ ุจุงุฒฺฏุฑุงู ุนุงู ุจูุฏ ู ุฏุงุณุชุงู ูู ุฑุง ูุฌุงูโุฒุฏู ฺฉุฑุฏ.\"\n",
    "\n",
    "# ุชุจุฏู ุฌููู ุจู ุชูฺฉูโูุง ูุฑูุฏ ูุฏู\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# ูพุดโุจู ุงุญุณุงุณ\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# ุงุนูุงู Softmax ุจุฑุง ุชุจุฏู ุจู ุงุญุชูุงู\n",
    "probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "# ููุงุด ูุชุงุฌ\n",
    "labels = [\"ููู ๐\", \"ุฎูุซ ๐\", \"ูุซุจุช ๐\"]\n",
    "predicted_label = labels[torch.argmax(probs)]\n",
    "\n",
    "print(\"ุฌููู:\", text)\n",
    "print(\"ุชุญูู ุงุญุณุงุณ:\", predicted_label)\n",
    "print(\"ุงุญุชูุงูโูุง:\", dict(zip(labels, np.round(probs.numpy()[0], 3))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34608cac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
