{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# سفر یادگیری: آشنایی با الگوریتم SVM 🚀📊\n",
    "\n",
    "**بیایید یکی از قدرتمندترین الگوریتم‌های یادگیری ماشین را کشف کنیم:**\n",
    "\n",
    "## <span style=\"color:#8e24aa;\">SVM (ماشین بردار پشتیبان)</span> 🧭  \n",
    "- **مرز دقیق بین دسته‌ها** ✂️  \n",
    "- به‌دنبال یافتن یک ابرصفحه (Hyperplane) است که بهترین تفکیک بین کلاس‌ها را داشته باشد  \n",
    "- نقاط نزدیک به مرز تصمیم‌گیری به نام <span style=\"color:#ff9800;\">Support Vectors</span> شناخته می‌شوند  \n",
    "- ایده‌آل برای داده‌های با ابعاد زیاد (High Dimensional) و مجموعه‌های کوچک  \n",
    "\n",
    "## 🛠️ چطور کار می‌کند؟\n",
    "- داده‌ها را در فضای n‌بعدی نگاشت می‌کند  \n",
    "- سعی می‌کند فاصله بین کلاس‌ها را **ماکزیمم** کند  \n",
    "- می‌تواند با هسته‌ها (Kernels) مرزهای غیرخطی هم بسازد!\n",
    "\n",
    "## 🧠 کاربردها:\n",
    "- تشخیص چهره 👤  \n",
    "- دسته‌بندی ایمیل‌ها (Spam vs Ham) 📬  \n",
    "- شناسایی الگوهای ژنتیکی 🧬  \n",
    "\n",
    "📌 **نکته طلایی:**  \n",
    "اگر داده‌ها جداپذیر نیستند، با استفاده از **هسته‌ها (Kernel Trick)** داده‌ها را به فضای بالاتری می‌برد که در آنجا جداپذیر باشند!\n",
    "\n",
    "🎯 **هدف ما در این مسیر:**  \n",
    "درک شهودی از مرز تصمیم‌گیری + آشنایی با Support Vectors + تمرین عملی با داده‌های واقعی\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# 📝 داده‌های متنی ساده با برچسب احساسات (0 = منفی، 1 = مثبت)\n",
    "texts = [\n",
    "    \"این فیلم عالی بود و خیلی دوستش داشتم\",\n",
    "    \"واقعا افتضاح بود، وقت تلف کردن بود\",\n",
    "    \"بازیگرها فوق‌العاده بودن و داستان جذاب بود\",\n",
    "    \"کسل‌کننده و بی‌محتوا، پیشنهاد نمی‌کنم\",\n",
    "    \"یکی از بهترین فیلم‌هایی که دیدم\",\n",
    "    \"خیلی بد بود، اصلاً خوشم نیومد\"\n",
    "]\n",
    "labels = [1, 0, 1, 0, 1, 0]  # برچسب‌ها\n",
    "\n",
    "# 🔧 ساخت pipeline: تبدیل متن به بردار + مدل SVM خطی\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "\n",
    "# 🧠 آموزش مدل\n",
    "model.fit(texts, labels)\n",
    "\n",
    "# 🧪 پیش‌بینی احساس جمله‌ی جدید\n",
    "new_text = \"فیلم خیلی قشنگ و الهام‌بخش بود\"\n",
    "prediction = model.predict([new_text])\n",
    "\n",
    "print(\"🌟 نتیجه تحلیل احساسات:\", \"مثبت\" if prediction[0] == 1 else \"منفی\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌳 درخت تصمیم (Decision Tree)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ چگونه کار می‌کند؟\n",
    "\n",
    "درخت تصمیم شبیه یک درخت منطقی است که در آن هر **گره (Node)** یک سؤال می‌پرسد و براساس پاسخ (مثلاً «بله» یا «خیر») به یکی از شاخه‌های بعدی می‌رویم.  \n",
    "در نهایت به **برگ (Leaf)** می‌رسیم که نتیجه نهایی (مثلاً «ایمیل اسپم است» یا «نیست») را تعیین می‌کند.\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 فرآیند اصلی\n",
    "\n",
    "1. **بررسی داده‌ها** برای پیدا کردن بهترین ویژگی (feature) جهت تقسیم داده‌ها.\n",
    "2. استفاده از معیارهایی مانند:\n",
    "    - Information Gain\n",
    "    - Gini Index\n",
    "3. الگوریتم مشخص می‌کند کدام ویژگی بیشترین اطلاعات را برای تصمیم‌گیری فراهم می‌کند.\n",
    "4. این روند **به‌صورت بازگشتی** تکرار می‌شود تا:\n",
    "    - همه داده‌ها به‌خوبی طبقه‌بندی شوند،\n",
    "    - یا به عمق مشخصی از درخت برسیم.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 کاربردهای مهم\n",
    "\n",
    "- ✅ شناسایی ایمیل‌های اسپم یا غیر اسپم\n",
    "- ✅ تحلیل احساسات در متون (مثبت / منفی / خنثی)\n",
    "- ✅ پیش‌بینی بیماری‌ها در داده‌های پزشکی\n",
    "- ✅ ارزیابی اعتبار مشتریان در امور بانکی\n",
    "- ✅ تصمیم‌گیری خودکار در سیستم‌های توصیه‌گر (Recommendation Systems)\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 خلاصه در یک جمله:\n",
    "\n",
    "> **درخت تصمیم، داده‌ها را با پرسش‌های متوالی تقسیم می‌کند تا در نهایت با منطق ساده و قابل فهم، بهترین تصمیم یا پیش‌بینی را ارائه دهد.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 📝 داده‌ها (مثال‌هایی از جمله‌هایی که احساس پنهان هم دارن)\n",
    "texts = [\n",
    "    \"این محصول عالی بود\",         # مثبت\n",
    "    \"افتضاحه، هیچ‌وقت نمی‌خرم\",    # منفی\n",
    "    \"می‌تونست بهتر باشه\",          # منفیِ ملایم (نشونه نارضایتی ناخودآگاه)\n",
    "    \"واقعا دوستش داشتم\",          # مثبت\n",
    "    \"نه بد بود نه خوب\",           # خنثی\n",
    "    \"بد نبود ولی عالی هم نبود\",   # خنثی / منفی ملایم\n",
    "    \"یکی از بهترین تجربه‌هام بود\", # مثبت\n",
    "    \"بی‌نظر بود، البته اگه مشکلش نبود\", # احساسی دوگانه (مخلوط)\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"negative\", \"positive\", \"neutral\", \"neutral\", \"positive\", \"negative\"]\n",
    "\n",
    "# 🔤 تبدیل متن به ویژگی عددی (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# 🎯 مدل و آموزش\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 📈 ارزیابی مدل\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 🔍 پیش‌بینی یک جمله جدید\n",
    "new_text = [\"خیلی هم جالب نبود\"]\n",
    "new_vec = vectorizer.transform(new_text)\n",
    "prediction = model.predict(new_vec)\n",
    "print(\"🌟 نتیجه تحلیل جمله:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🍃 الگوریتم: Random Forests (جنگل تصادفی)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ چگونه کار می‌کند؟\n",
    "\n",
    "الگوریتم **Random Forest** در واقع مجموعه‌ای از چندین **درخت تصمیم** (Decision Trees) است که به‌صورت گروهی با هم همکاری می‌کنند!\n",
    "\n",
    "🧠 **ایده اصلی:**  \n",
    "اگر از چندین درخت که هرکدام به‌صورت تصادفی آموزش دیده‌اند نظر بگیریم،  \n",
    "نتیجه‌ی نهایی **دقیق‌تر، پایدارتر** و **کم‌خطاتر** خواهد بود.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 مراحل اجرا\n",
    "\n",
    "1. **ساخت چندین درخت تصمیم** به‌صورت مستقل.\n",
    "2. هر درخت فقط **بخشی از داده‌ها** را (با جایگزینی) و **بخشی از ویژگی‌ها** را می‌بیند → ایجاد تصادفی بودن (Randomness).\n",
    "3. هر درخت به‌تنهایی پیش‌بینی می‌کند.\n",
    "4. **رأی‌گیری** (در طبقه‌بندی/Classification) یا **میانگین‌گیری** (در رگرسیون/Regression) روی نتایج همه درخت‌ها انجام می‌شود.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 کاربردهای مهم\n",
    "\n",
    "- ✅ تشخیص ایمیل‌های Spam یا Not Spam\n",
    "- ✅ تحلیل احساسات (مثبت / منفی / خنثی)\n",
    "- ✅ تحلیل نظرات کاربران در اپلیکیشن‌ها یا فروشگاه‌ها\n",
    "- ✅ شناسایی رفتار کاربران در شبکه‌های اجتماعی\n",
    "- ✅ تشخیص بیماری‌ها در پزشکی\n",
    "- ✅ پیش‌بینی تقلب‌های مالی\n",
    "- ✅ مدل‌های شناختی برای تحلیل لحن و احساسات ناخودآگاه\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 خلاصه در یک جمله:\n",
    "\n",
    "> **جنگل تصادفی، با ترکیب نتایج چندین درخت تصمیم تصادفی، پیش‌بینی‌هایی قوی، پایدار و دقیق‌تر ارائه می‌دهد و نسبت به مدل‌های تکی کمتر دچار خطا می‌شود.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# داده‌های نمونه (دارای احساس مستقیم و غیرمستقیم)\n",
    "texts = [\n",
    "    \"واقعا عالی بود\",              # مثبت\n",
    "    \"هیچ وقت نمی‌خرم دیگه\",        # منفی\n",
    "    \"نه خوب بود نه بد\",           # خنثی\n",
    "    \"دوسش داشتم\",                  # مثبت\n",
    "    \"بد نبود ولی بازم نمی‌خرم\",    # منفی پنهان\n",
    "    \"پیشنهاد نمی‌کنم\",             # منفی\n",
    "    \"ارزش خرید داشت\",             # مثبت\n",
    "    \"متوسط بود\",                  # خنثی/پنهان\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"negative\", \"positive\", \"neutral\"]\n",
    "\n",
    "# پردازش متن به ویژگی‌های عددی\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# آموزش مدل\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ارزیابی\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# پیش‌بینی احساس پنهان یک جمله\n",
    "sentence = [\"نه خیلی خوب بود نه خیلی بد ولی یه چیزی کم داشت\"]\n",
    "vector = vectorizer.transform([sentence[0]])\n",
    "prediction = model.predict(vector)\n",
    "print(\"🔍 احساس پیش‌بینی‌شده:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 👥 K-Nearest Neighbors (KNN)  \n",
    "### یا الگوریتم k تا نزدیک‌ترین همسایه\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ چگونه کار می‌کند؟\n",
    "\n",
    "**KNN** یکی از ساده‌ترین و در عین حال مؤثرترین الگوریتم‌های یادگیری ماشین است که بر پایه‌ی \"نزدیکی\" یا شباهت بین داده‌ها تصمیم‌گیری می‌کند.\n",
    "\n",
    "---\n",
    "\n",
    "### مراحل اجرا\n",
    "\n",
    "1. **ورود یک نمونه جدید** (مثلاً یک جمله یا تصویر)\n",
    "2. پیدا کردن **k تا نزدیک‌ترین همسایه** به آن نمونه (با استفاده از معیار فاصله، مثل فاصله اقلیدسی)\n",
    "3. بررسی برچسب همسایه‌ها:\n",
    "    - اگر اکثریت **مثبت** باشند → نتیجه مثبت است.\n",
    "    - اگر اکثریت **منفی** باشند → نتیجه منفی است.\n",
    "\n",
    "> **KNN هیچ مدلی نمی‌سازد؛ فقط داده‌ها را ذخیره می‌کند و هنگام نیاز از آن‌ها استفاده می‌کند. به این نوع الگوریتم‌ها Lazy Learning گفته می‌شود.**\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 کاربردهای KNN\n",
    "\n",
    "- ✅ تشخیص احساسات در متن (مثبت / منفی / خنثی)\n",
    "- ✅ دسته‌بندی تصاویر (مثل گربه/سگ)\n",
    "- ✅ شناسایی ایمیل‌های اسپم\n",
    "- ✅ تشخیص بیماری بر اساس علائم مشابه\n",
    "- ✅ تحلیل گفتار افراد برای فهم ناخودآگاه (به‌ویژه وقتی بیان غیرمستقیم دارند)\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 خلاصه در یک جمله:\n",
    "\n",
    "> **KNN، بدون ساختن مدل، با مقایسه‌ی یک نمونه جدید با نزدیک‌ترین همسایه‌ها در داده‌های قبلی، تصمیم نهایی را تعیین می‌کند.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# داده‌های ساده\n",
    "texts = [\n",
    "    \"خیلی عالی بود\",          # مثبت\n",
    "    \"اصلاً راضی نبودم\",       # منفی\n",
    "    \"نه خیلی بد بود نه خوب\",  # خنثی\n",
    "    \"عاشقش شدم\",              # مثبت\n",
    "    \"خرید بدی بود\",           # منفی\n",
    "    \"معمولی بود\",             # خنثی\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# تبدیل متن به بردار عددی\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# مدل و آموزش\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=0)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ارزیابی\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# پیش‌بینی جمله جدید\n",
    "sentence = [\"تجربه‌ی خوبی نبود راستش\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "pred = model.predict(vec)\n",
    "print(\"🔍 احساس شناسایی‌شده:\", pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Naive Bayes (بایز ساده)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ چگونه کار می‌کند؟\n",
    "\n",
    "**Naive Bayes** یک الگوریتم مبتنی بر احتمال است که از **قانون بایز (Bayes' Theorem)** استفاده می‌کند.  \n",
    "این قانون به ما می‌گوید:  \n",
    "وقتی یک ویژگی (مثلاً یک کلمه) دیده شد، چقدر احتمال دارد جمله متعلق به یک کلاس خاص باشد (مثلاً «مثبت» یا «منفی»).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 نکته جالب\n",
    "\n",
    "- **فرض مهم:** همه ویژگی‌ها (مثلاً کلمات) کاملاً مستقل از هم هستند.  \n",
    "  (در عمل همیشه درست نیست، ولی الگوریتم خیلی خوب جواب می‌دهد!)\n",
    "- این فرض ساده‌انگارانه باعث می‌شود مدل بسیار **سریع** و **سبک** باشد.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 کاربردهای Naive Bayes\n",
    "\n",
    "- ✅ تحلیل احساسات (Sentiment Analysis)\n",
    "- ✅ تشخیص اسپم یا ایمیل سالم\n",
    "- ✅ دسته‌بندی متون (اخبار، نظرات، پیام‌ها)\n",
    "- ✅ تشخیص زبان\n",
    "- ✅ پیش‌بینی نیت پنهان یا احساس غیرمستقیم\n",
    "- ✅ طبقه‌بندی اسناد یا دسته‌بندی کاربران بر اساس رفتار\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 خلاصه در یک جمله:\n",
    "\n",
    "> **بایز ساده، با فرض مستقل بودن ویژگی‌ها و با محاسبات سریع احتمال، یکی از کارآمدترین الگوریتم‌ها برای طبقه‌بندی سریع داده‌ها است.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# داده‌های نمونه\n",
    "texts = [\n",
    "    \"خیلی خوب بود\",               # مثبت\n",
    "    \"افتضاح بود، اصلاً دوست نداشتم\", # منفی\n",
    "    \"نه بد بود نه خوب\",           # خنثی\n",
    "    \"عاشق این محصول شدم\",         # مثبت\n",
    "    \"نمی‌خرم دیگه\",               # منفی\n",
    "    \"معمولی بود\",                 # خنثی\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# تبدیل متن به بردار عددی\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# آموزش مدل\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=0)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ارزیابی\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# پیش‌بینی یک جمله‌ی پنهان‌احساس\n",
    "sentence = [\"بد نبود ولی حس خوبی نداشتم\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "prediction = model.predict(vec)\n",
    "print(\"🔍 احساس شناسایی‌شده:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚡️ Gradient Boosting Machines (ماشین‌های گرادیان بوستینگ)\n",
    "گاهی بهش می‌گن: **GBM** یا «بوستینگ تدریجی گرادیان»\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ چگونه کار می‌کند؟\n",
    "\n",
    "الگوریتم **GBM** یکی از قوی‌ترین روش‌ها در یادگیری ماشین برای دسته‌بندی (Classification) و رگرسیون (Regression) است.\n",
    "\n",
    "- ابتدا یک مدل ضعیف (مانند یک درخت تصمیم کوچک) ساخته می‌شود.\n",
    "- مدل دوم ساخته می‌شود تا **اشتباهات مدل قبلی** را اصلاح کند.\n",
    "- این فرآیند به‌صورت تدریجی و تکراری ادامه می‌یابد؛ هر مدل جدید سعی می‌کند **خطاهای قبلی** را جبران کند.\n",
    "- در پایان، همه مدل‌ها با هم ترکیب می‌شوند تا یک **مدل قوی و دقیق** بسازند.\n",
    "\n",
    "🌱 **بوستینگ** یعنی تقویت تدریجی مدل‌ها.  \n",
    "📉 **گرادیان** یعنی حرکت به سمت کاهش خطاها با استفاده از شیب (gradient) خطاها.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 کاربردهای مهم GBM\n",
    "\n",
    "- **تحلیل احساسات (Sentiment Analysis):**  \n",
    "  تشخیص دقیق احساسات مثبت، منفی یا خنثی، حتی در جملات پیچیده یا چندمعنایی ✨\n",
    "\n",
    "- **تحلیل ناخودآگاه در متون:**  \n",
    "  شناسایی لحن یا احساسات پنهان (مثلاً جملات طعنه‌آمیز یا غیرمستقیم) 😌\n",
    "\n",
    "- **تشخیص اسپم:**  \n",
    "  شناسایی ایمیل‌ها یا پیام‌های اسپم، حتی اگر حرفه‌ای و شبیه پیام‌های معمولی نوشته شده باشند.\n",
    "\n",
    "- **سیستم‌های پیشنهاددهنده (Recommendation Systems):**  \n",
    "  پیشنهاد فیلم، کتاب یا محصول بر اساس الگوهای خرید و واکنش کاربران.\n",
    "\n",
    "- **پیش‌بینی رفتار کاربر:**  \n",
    "  پیش‌بینی احساسات یا تصمیم‌های آینده کاربر بر اساس رفتارهای قبلی 🧠\n",
    "\n",
    "- **پیش‌بینی در بازارهای مالی:**  \n",
    "  شناسایی روابط غیرخطی بین پارامترهای مالی و پیش‌بینی قیمت یا ریسک 📉📈\n",
    "\n",
    "- **پزشکی و سلامت روان:**  \n",
    "  تحلیل گزارش‌ها، علائم بیماران یا یادداشت‌های روان‌شناسی برای کشف الگوهای پنهان و تشخیص زودهنگام بیماری‌ها.\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 خلاصه در یک جمله:\n",
    "\n",
    "> **GBM با ترکیب مدل‌های ضعیف و اصلاح تدریجی خطاها، یکی از قدرتمندترین و دقیق‌ترین الگوریتم‌ها برای پیش‌بینی و تحلیل داده‌های پیچیده است.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# داده‌های نمونه\n",
    "texts = [\n",
    "    \"خیلی خوشم اومد\",        # مثبت\n",
    "    \"افتضاح بود\",             # منفی\n",
    "    \"نه خوب بود نه بد\",      # خنثی\n",
    "    \"عاشق این محصول شدم\",     # مثبت\n",
    "    \"واقعا پشیمونم\",          # منفی\n",
    "    \"معمولی بود\",            # خنثی\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# بردارسازی متن\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# آموزش مدل\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# ارزیابی\n",
    "y_pred = model.predict(X_test.toarray())\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# پیش‌بینی یک جمله‌ی احساس‌پنهان\n",
    "sentence = [\"مثلاً چیز خوبی بود\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "prediction = model.predict(vec.toarray())\n",
    "print(\"🔍 احساس شناسایی‌شده:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔢 Logistic Regression (رگرسیون لجستیک)\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ چگونه کار می‌کند؟\n",
    "\n",
    "**رگرسیون لجستیک** برخلاف اسمش، برای **طبقه‌بندی (Classification)** استفاده می‌شود، نه رگرسیون عددی!  \n",
    "هدف آن محاسبه احتمال تعلق یک ورودی به یک کلاس خاص است، مثلاً:\n",
    "\n",
    "> «این جمله احتمالاً ۹۰٪ احساس مثبته و ۱۰٪ منفی.»\n",
    "\n",
    "- **فرمول اصلی:**  \n",
    "  تابع سیگموید (Sigmoid Function) که خروجی را بین ۰ و ۱ نگه می‌دارد؛ این مقدار همان احتمال تعلق به یک کلاس خاص است.\n",
    "\n",
    "---\n",
    "\n",
    "## 🌍 کاربردهای مهم\n",
    "\n",
    "- **تحلیل احساسات (Sentiment Analysis):**  \n",
    "  تشخیص مثبت یا منفی بودن نظرات، توییت‌ها، پیام‌ها و نقدها.\n",
    "\n",
    "- **تشخیص اسپم:**  \n",
    "  پیش‌بینی احتمال اسپم بودن ایمیل‌ها یا پیام‌ها.\n",
    "\n",
    "- **تحلیل ناخودآگاه و لحن:**  \n",
    "  حدس زدن احساس واقعی یا لحن پشت یک جمله بر اساس انتخاب کلمات و نحوه بیان.\n",
    "\n",
    "- **تشخیص بیماری بر اساس داده‌های پزشکی:**  \n",
    "  مثلاً پیش‌بینی احتمال افسردگی یا بیماری دیگر از روی داده‌های متنی/عددی.\n",
    "\n",
    "- **پیش‌بینی نرخ ریزش کاربران (Churn Prediction):**  \n",
    "  آیا کاربر اپلیکیشن یا سایت را ترک می‌کند یا نه؟\n",
    "\n",
    "- **تشخیص تقلب (Fraud Detection):**  \n",
    "  سنجش احتمال تقلب در تراکنش‌های بانکی یا خریدها.\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 خلاصه در یک جمله:\n",
    "\n",
    "> **رگرسیون لجستیک، با استفاده از تابع سیگموید، احتمال تعلق یک نمونه به هر کلاس را تخمین می‌زند و به طبقه‌بندی داده‌ها کمک می‌کند.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# داده‌های آموزشی\n",
    "texts = [\"I love this!\", \"This is bad\", \"What a great movie\", \"Horrible experience\"]\n",
    "labels = [1, 0, 1, 0]  # 1 = مثبت، 0 = منفی\n",
    "\n",
    "# تبدیل متن به ویژگی عددی\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# آموزش مدل\n",
    "model = LogisticRegression()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# تست\n",
    "test_text = [\"I hate this movie\"]\n",
    "test_vec = vectorizer.transform(test_text)\n",
    "prediction = model.predict(test_vec)\n",
    "\n",
    "print(\"Prediction:\", \"مثبت\" if prediction[0] == 1 else \"منفی\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
