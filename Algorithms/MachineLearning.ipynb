{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# سفر یادگیری: آشنایی با الگوریتم SVM 🚀📊\n",
    "\n",
    "**بیایید یکی از قدرتمندترین الگوریتم‌های یادگیری ماشین را کشف کنیم:**\n",
    "\n",
    "## <span style=\"color:#8e24aa;\">SVM (ماشین بردار پشتیبان)</span> 🧭  \n",
    "- **مرز دقیق بین دسته‌ها** ✂️  \n",
    "- به‌دنبال یافتن یک ابرصفحه (Hyperplane) است که بهترین تفکیک بین کلاس‌ها را داشته باشد  \n",
    "- نقاط نزدیک به مرز تصمیم‌گیری به نام <span style=\"color:#ff9800;\">Support Vectors</span> شناخته می‌شوند  \n",
    "- ایده‌آل برای داده‌های با ابعاد زیاد (High Dimensional) و مجموعه‌های کوچک  \n",
    "\n",
    "## 🛠️ چطور کار می‌کند؟\n",
    "- داده‌ها را در فضای n‌بعدی نگاشت می‌کند  \n",
    "- سعی می‌کند فاصله بین کلاس‌ها را **ماکزیمم** کند  \n",
    "- می‌تواند با هسته‌ها (Kernels) مرزهای غیرخطی هم بسازد!\n",
    "\n",
    "## 🧠 کاربردها:\n",
    "- تشخیص چهره 👤  \n",
    "- دسته‌بندی ایمیل‌ها (Spam vs Ham) 📬  \n",
    "- شناسایی الگوهای ژنتیکی 🧬  \n",
    "\n",
    "📌 **نکته طلایی:**  \n",
    "اگر داده‌ها جداپذیر نیستند، با استفاده از **هسته‌ها (Kernel Trick)** داده‌ها را به فضای بالاتری می‌برد که در آنجا جداپذیر باشند!\n",
    "\n",
    "🎯 **هدف ما در این مسیر:**  \n",
    "درک شهودی از مرز تصمیم‌گیری + آشنایی با Support Vectors + تمرین عملی با داده‌های واقعی\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# 📝 داده‌های متنی ساده با برچسب احساسات (0 = منفی، 1 = مثبت)\n",
    "texts = [\n",
    "    \"این فیلم عالی بود و خیلی دوستش داشتم\",\n",
    "    \"واقعا افتضاح بود، وقت تلف کردن بود\",\n",
    "    \"بازیگرها فوق‌العاده بودن و داستان جذاب بود\",\n",
    "    \"کسل‌کننده و بی‌محتوا، پیشنهاد نمی‌کنم\",\n",
    "    \"یکی از بهترین فیلم‌هایی که دیدم\",\n",
    "    \"خیلی بد بود، اصلاً خوشم نیومد\"\n",
    "]\n",
    "labels = [1, 0, 1, 0, 1, 0]  # برچسب‌ها\n",
    "\n",
    "# 🔧 ساخت pipeline: تبدیل متن به بردار + مدل SVM خطی\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "\n",
    "# 🧠 آموزش مدل\n",
    "model.fit(texts, labels)\n",
    "\n",
    "# 🧪 پیش‌بینی احساس جمله‌ی جدید\n",
    "new_text = \"فیلم خیلی قشنگ و الهام‌بخش بود\"\n",
    "prediction = model.predict([new_text])\n",
    "\n",
    "print(\"🌟 نتیجه تحلیل احساسات:\", \"مثبت\" if prediction[0] == 1 else \"منفی\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "درخت تصمیم (Decision Tree)\n",
    "\n",
    "⚙️ چطور کار می‌کند؟\n",
    "درخت تصمیم مانند یک درخت منطقی رفتار می‌کند که در آن هر گره (Node) یک سوال می‌پرسد و بر اساس جواب آن (مثلاً «بله» یا «خیر»)، به سمت شاخه‌های بعدی حرکت می‌کنیم تا در نهایت به یک برگ (Leaf) برسیم که نتیجه نهایی (مثلاً «ایمیل اسپم است» یا «نیست») را مشخص می‌کند.\n",
    "\n",
    "💡 فرآیند اصلی به این صورت است:\n",
    "\n",
    "داده‌ها بررسی می‌شوند تا بهترین ویژگی (feature) برای تقسیم آن‌ها پیدا شود.\n",
    "\n",
    "با استفاده از معیارهایی مانند:\n",
    "\n",
    "Information Gain\n",
    "\n",
    "Gini Index\n",
    "الگوریتم مشخص می‌کند که کدام ویژگی بیشترین اطلاعات را برای تصمیم‌گیری می‌دهد.\n",
    "\n",
    "این روند به‌صورت بازگشتی ادامه پیدا می‌کند تا زمانی که:\n",
    "\n",
    "همه داده‌ها به‌خوبی طبقه‌بندی شده باشند\n",
    "\n",
    "یا به عمق مشخصی از درخت برسیم.\n",
    "\n",
    "🎯 کاربردها:\n",
    "درخت تصمیم یکی از پراستفاده‌ترین الگوریتم‌های یادگیری ماشین در کاربردهای زیر است:\n",
    "\n",
    "✅ شناسایی ایمیل‌های اسپم یا غیر اسپم\n",
    "\n",
    "✅ تحلیل احساسات در متون (مثبت / منفی / خنثی)\n",
    "\n",
    "✅ پیش‌بینی بیماری‌ها در داده‌های پزشکی\n",
    "\n",
    "✅ ارزیابی اعتبار مشتریان در امور بانکی\n",
    "\n",
    "✅ تصمیم‌گیری خودکار در سیستم‌های توصیه‌گر (Recommendation Systems)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 📝 داده‌ها (مثال‌هایی از جمله‌هایی که احساس پنهان هم دارن)\n",
    "texts = [\n",
    "    \"این محصول عالی بود\",         # مثبت\n",
    "    \"افتضاحه، هیچ‌وقت نمی‌خرم\",    # منفی\n",
    "    \"می‌تونست بهتر باشه\",          # منفیِ ملایم (نشونه نارضایتی ناخودآگاه)\n",
    "    \"واقعا دوستش داشتم\",          # مثبت\n",
    "    \"نه بد بود نه خوب\",           # خنثی\n",
    "    \"بد نبود ولی عالی هم نبود\",   # خنثی / منفی ملایم\n",
    "    \"یکی از بهترین تجربه‌هام بود\", # مثبت\n",
    "    \"بی‌نظر بود، البته اگه مشکلش نبود\", # احساسی دوگانه (مخلوط)\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"negative\", \"positive\", \"neutral\", \"neutral\", \"positive\", \"negative\"]\n",
    "\n",
    "# 🔤 تبدیل متن به ویژگی عددی (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# 🎯 مدل و آموزش\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 📈 ارزیابی مدل\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 🔍 پیش‌بینی یک جمله جدید\n",
    "new_text = [\"خیلی هم جالب نبود\"]\n",
    "new_vec = vectorizer.transform(new_text)\n",
    "prediction = model.predict(new_vec)\n",
    "print(\"🌟 نتیجه تحلیل جمله:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🍃 الگوریتم: Random Forests (جنگل تصادفی)\n",
    "⚙️ چطور کار می‌کند؟\n",
    "الگوریتم Random Forest در واقع مجموعه‌ای از درخت‌های تصمیم (Decision Trees) هست که با هم همکاری می‌کنن!\n",
    "🧠 ایده‌اش اینه که:\n",
    "\n",
    "«اگه از چندین درخت که به‌صورت تصادفی آموزش دیده‌ان نظر بگیریم، نتیجه‌ی نهایی دقیق‌تر، پایدارتر و کمتر دچار اشتباه خواهد بود.»\n",
    "\n",
    "🔍 مراحل کار:\n",
    "\n",
    "چندین درخت تصمیم به صورت مستقل ساخته می‌شن.\n",
    "\n",
    "هر درخت فقط بخشی از داده‌ها رو (با جایگزینی) و بخشی از ویژگی‌ها رو می‌بینه → تصادفی بودن\n",
    "\n",
    "هر درخت به تنهایی پیش‌بینی می‌کنه.\n",
    "\n",
    "رأی‌گیری (برای Classification) یا میانگین‌گیری (برای Regression) انجام می‌شه.\n",
    "\n",
    "🎯 کاربردها\n",
    "✅ تشخیص ایمیل‌های Spam یا Not Spam\n",
    "✅ تحلیل احساسات (مثبت / منفی / خنثی)\n",
    "✅ تحلیل نظرات کاربران در اپلیکیشن‌ها یا فروشگاه‌ها\n",
    "✅ شناسایی رفتار کاربران در شبکه‌های اجتماعی\n",
    "✅ تشخیص بیماری‌ها در پزشکی\n",
    "✅ پیش‌بینی تقلب‌های مالی\n",
    "✅ مدل‌های شناختی برای تحلیل لحن و احساسات ناخودآگاه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# داده‌های نمونه (دارای احساس مستقیم و غیرمستقیم)\n",
    "texts = [\n",
    "    \"واقعا عالی بود\",              # مثبت\n",
    "    \"هیچ وقت نمی‌خرم دیگه\",        # منفی\n",
    "    \"نه خوب بود نه بد\",           # خنثی\n",
    "    \"دوسش داشتم\",                  # مثبت\n",
    "    \"بد نبود ولی بازم نمی‌خرم\",    # منفی پنهان\n",
    "    \"پیشنهاد نمی‌کنم\",             # منفی\n",
    "    \"ارزش خرید داشت\",             # مثبت\n",
    "    \"متوسط بود\",                  # خنثی/پنهان\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"negative\", \"positive\", \"neutral\"]\n",
    "\n",
    "# پردازش متن به ویژگی‌های عددی\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# آموزش مدل\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ارزیابی\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# پیش‌بینی احساس پنهان یک جمله\n",
    "sentence = [\"نه خیلی خوب بود نه خیلی بد ولی یه چیزی کم داشت\"]\n",
    "vector = vectorizer.transform([sentence[0]])\n",
    "prediction = model.predict(vector)\n",
    "print(\"🔍 احساس پیش‌بینی‌شده:\", prediction[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
