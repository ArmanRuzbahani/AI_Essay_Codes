{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ุณูุฑ ุงุฏฺฏุฑ: ุขุดูุง ุจุง ุงูฺฏูุฑุชู SVM ๐๐\n",
    "\n",
    "**ุจุงุฏ ฺฉ ุงุฒ ูุฏุฑุชููุฏุชุฑู ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ูุงุดู ุฑุง ฺฉุดู ฺฉูู:**\n",
    "\n",
    "## <span style=\"color:#8e24aa;\">SVM (ูุงุดู ุจุฑุฏุงุฑ ูพุดุชุจุงู)</span> ๐งญ  \n",
    "- **ูุฑุฒ ุฏูู ุจู ุฏุณุชูโูุง** โ๏ธ  \n",
    "- ุจูโุฏูุจุงู ุงูุชู ฺฉ ุงุจุฑุตูุญู (Hyperplane) ุงุณุช ฺฉู ุจูุชุฑู ุชูฺฉฺฉ ุจู ฺฉูุงุณโูุง ุฑุง ุฏุงุดุชู ุจุงุดุฏ  \n",
    "- ููุงุท ูุฒุฏฺฉ ุจู ูุฑุฒ ุชุตููโฺฏุฑ ุจู ูุงู <span style=\"color:#ff9800;\">Support Vectors</span> ุดูุงุฎุชู ูโุดููุฏ  \n",
    "- ุงุฏูโุขู ุจุฑุง ุฏุงุฏูโูุง ุจุง ุงุจุนุงุฏ ุฒุงุฏ (High Dimensional) ู ูุฌููุนูโูุง ฺฉูฺฺฉ  \n",
    "\n",
    "## ๐๏ธ ฺุทูุฑ ฺฉุงุฑ ูโฺฉูุฏุ\n",
    "- ุฏุงุฏูโูุง ุฑุง ุฏุฑ ูุถุง nโุจุนุฏ ูฺฏุงุดุช ูโฺฉูุฏ  \n",
    "- ุณุน ูโฺฉูุฏ ูุงุตูู ุจู ฺฉูุงุณโูุง ุฑุง **ูุงฺฉุฒูู** ฺฉูุฏ  \n",
    "- ูโุชูุงูุฏ ุจุง ูุณุชูโูุง (Kernels) ูุฑุฒูุง ุบุฑุฎุท ูู ุจุณุงุฒุฏ!\n",
    "\n",
    "## ๐ง ฺฉุงุฑุจุฑุฏูุง:\n",
    "- ุชุดุฎุต ฺูุฑู ๐ค  \n",
    "- ุฏุณุชูโุจูุฏ ุงููโูุง (Spam vs Ham) ๐ฌ  \n",
    "- ุดูุงุณุง ุงูฺฏููุง ฺูุชฺฉ ๐งฌ  \n",
    "\n",
    "๐ **ูฺฉุชู ุทูุง:**  \n",
    "ุงฺฏุฑ ุฏุงุฏูโูุง ุฌุฏุงูพุฐุฑ ูุณุชูุฏุ ุจุง ุงุณุชูุงุฏู ุงุฒ **ูุณุชูโูุง (Kernel Trick)** ุฏุงุฏูโูุง ุฑุง ุจู ูุถุง ุจุงูุงุชุฑ ูโุจุฑุฏ ฺฉู ุฏุฑ ุขูุฌุง ุฌุฏุงูพุฐุฑ ุจุงุดูุฏ!\n",
    "\n",
    "๐ฏ **ูุฏู ูุง ุฏุฑ ุงู ูุณุฑ:**  \n",
    "ุฏุฑฺฉ ุดููุฏ ุงุฒ ูุฑุฒ ุชุตููโฺฏุฑ + ุขุดูุง ุจุง Support Vectors + ุชูุฑู ุนูู ุจุง ุฏุงุฏูโูุง ูุงูุน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# ๐ ุฏุงุฏูโูุง ูุชู ุณุงุฏู ุจุง ุจุฑฺุณุจ ุงุญุณุงุณุงุช (0 = ูููุ 1 = ูุซุจุช)\n",
    "texts = [\n",
    "    \"ุงู ููู ุนุงู ุจูุฏ ู ุฎู ุฏูุณุชุด ุฏุงุดุชู\",\n",
    "    \"ูุงูุนุง ุงูุชุถุงุญ ุจูุฏุ ููุช ุชูู ฺฉุฑุฏู ุจูุฏ\",\n",
    "    \"ุจุงุฒฺฏุฑูุง ูููโุงูุนุงุฏู ุจูุฏู ู ุฏุงุณุชุงู ุฌุฐุงุจ ุจูุฏ\",\n",
    "    \"ฺฉุณูโฺฉููุฏู ู ุจโูุญุชูุงุ ูพุดููุงุฏ ููโฺฉูู\",\n",
    "    \"ฺฉ ุงุฒ ุจูุชุฑู ูููโูุง ฺฉู ุฏุฏู\",\n",
    "    \"ุฎู ุจุฏ ุจูุฏุ ุงุตูุงู ุฎูุดู ูููุฏ\"\n",
    "]\n",
    "labels = [1, 0, 1, 0, 1, 0]  # ุจุฑฺุณุจโูุง\n",
    "\n",
    "# ๐ง ุณุงุฎุช pipeline: ุชุจุฏู ูุชู ุจู ุจุฑุฏุงุฑ + ูุฏู SVM ุฎุท\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "\n",
    "# ๐ง ุขููุฒุด ูุฏู\n",
    "model.fit(texts, labels)\n",
    "\n",
    "# ๐งช ูพุดโุจู ุงุญุณุงุณ ุฌูููโ ุฌุฏุฏ\n",
    "new_text = \"ููู ุฎู ูุดูฺฏ ู ุงููุงูโุจุฎุด ุจูุฏ\"\n",
    "prediction = model.predict([new_text])\n",
    "\n",
    "print(\"๐ ูุชุฌู ุชุญูู ุงุญุณุงุณุงุช:\", \"ูุซุจุช\" if prediction[0] == 1 else \"ููู\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ุฏุฑุฎุช ุชุตูู (Decision Tree)\n",
    "\n",
    "โ๏ธ ฺุทูุฑ ฺฉุงุฑ ูโฺฉูุฏุ\n",
    "ุฏุฑุฎุช ุชุตูู ูุงููุฏ ฺฉ ุฏุฑุฎุช ููุทู ุฑูุชุงุฑ ูโฺฉูุฏ ฺฉู ุฏุฑ ุขู ูุฑ ฺฏุฑู (Node) ฺฉ ุณูุงู ูโูพุฑุณุฏ ู ุจุฑ ุงุณุงุณ ุฌูุงุจ ุขู (ูุซูุงู ยซุจููยป ุง ยซุฎุฑยป)ุ ุจู ุณูุช ุดุงุฎูโูุง ุจุนุฏ ุญุฑฺฉุช ูโฺฉูู ุชุง ุฏุฑ ููุงุช ุจู ฺฉ ุจุฑฺฏ (Leaf) ุจุฑุณู ฺฉู ูุชุฌู ููุง (ูุซูุงู ยซุงูู ุงุณูพู ุงุณุชยป ุง ยซูุณุชยป) ุฑุง ูุดุฎุต ูโฺฉูุฏ.\n",
    "\n",
    "๐ก ูุฑุขูุฏ ุงุตู ุจู ุงู ุตูุฑุช ุงุณุช:\n",
    "\n",
    "ุฏุงุฏูโูุง ุจุฑุฑุณ ูโุดููุฏ ุชุง ุจูุชุฑู ูฺฺฏ (feature) ุจุฑุง ุชูุณู ุขูโูุง ูพุฏุง ุดูุฏ.\n",
    "\n",
    "ุจุง ุงุณุชูุงุฏู ุงุฒ ูุนุงุฑูุง ูุงููุฏ:\n",
    "\n",
    "Information Gain\n",
    "\n",
    "Gini Index\n",
    "ุงูฺฏูุฑุชู ูุดุฎุต ูโฺฉูุฏ ฺฉู ฺฉุฏุงู ูฺฺฏ ุจุดุชุฑู ุงุทูุงุนุงุช ุฑุง ุจุฑุง ุชุตููโฺฏุฑ ูโุฏูุฏ.\n",
    "\n",
    "ุงู ุฑููุฏ ุจูโุตูุฑุช ุจุงุฒฺฏุดุช ุงุฏุงูู ูพุฏุง ูโฺฉูุฏ ุชุง ุฒูุงู ฺฉู:\n",
    "\n",
    "ููู ุฏุงุฏูโูุง ุจูโุฎูุจ ุทุจููโุจูุฏ ุดุฏู ุจุงุดูุฏ\n",
    "\n",
    "ุง ุจู ุนูู ูุดุฎุต ุงุฒ ุฏุฑุฎุช ุจุฑุณู.\n",
    "\n",
    "๐ฏ ฺฉุงุฑุจุฑุฏูุง:\n",
    "ุฏุฑุฎุช ุชุตูู ฺฉ ุงุฒ ูพุฑุงุณุชูุงุฏูโุชุฑู ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ูุงุดู ุฏุฑ ฺฉุงุฑุจุฑุฏูุง ุฒุฑ ุงุณุช:\n",
    "\n",
    "โ ุดูุงุณุง ุงููโูุง ุงุณูพู ุง ุบุฑ ุงุณูพู\n",
    "\n",
    "โ ุชุญูู ุงุญุณุงุณุงุช ุฏุฑ ูุชูู (ูุซุจุช / ููู / ุฎูุซ)\n",
    "\n",
    "โ ูพุดโุจู ุจูุงุฑโูุง ุฏุฑ ุฏุงุฏูโูุง ูพุฒุดฺฉ\n",
    "\n",
    "โ ุงุฑุฒุงุจ ุงุนุชุจุงุฑ ูุดุชุฑุงู ุฏุฑ ุงููุฑ ุจุงูฺฉ\n",
    "\n",
    "โ ุชุตููโฺฏุฑ ุฎูุฏฺฉุงุฑ ุฏุฑ ุณุณุชูโูุง ุชูุตูโฺฏุฑ (Recommendation Systems)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ๐ ุฏุงุฏูโูุง (ูุซุงูโูุง ุงุฒ ุฌูููโูุง ฺฉู ุงุญุณุงุณ ูพููุงู ูู ุฏุงุฑู)\n",
    "texts = [\n",
    "    \"ุงู ูุญุตูู ุนุงู ุจูุฏ\",         # ูุซุจุช\n",
    "    \"ุงูุชุถุงุญูุ ูฺโููุช ููโุฎุฑู\",    # ููู\n",
    "    \"ูโุชููุณุช ุจูุชุฑ ุจุงุดู\",          # ูููู ููุงู (ูุดููู ูุงุฑุถุงุช ูุงุฎูุฏุขฺฏุงู)\n",
    "    \"ูุงูุนุง ุฏูุณุชุด ุฏุงุดุชู\",          # ูุซุจุช\n",
    "    \"ูู ุจุฏ ุจูุฏ ูู ุฎูุจ\",           # ุฎูุซ\n",
    "    \"ุจุฏ ูุจูุฏ ูู ุนุงู ูู ูุจูุฏ\",   # ุฎูุซ / ููู ููุงู\n",
    "    \"ฺฉ ุงุฒ ุจูุชุฑู ุชุฌุฑุจูโูุงู ุจูุฏ\", # ูุซุจุช\n",
    "    \"ุจโูุธุฑ ุจูุฏุ ุงูุจุชู ุงฺฏู ูุดฺฉูุด ูุจูุฏ\", # ุงุญุณุงุณ ุฏูฺฏุงูู (ูุฎููุท)\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"negative\", \"positive\", \"neutral\", \"neutral\", \"positive\", \"negative\"]\n",
    "\n",
    "# ๐ค ุชุจุฏู ูุชู ุจู ูฺฺฏ ุนุฏุฏ (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ๐ฏ ูุฏู ู ุขููุฒุด\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ๐ ุงุฑุฒุงุจ ูุฏู\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ๐ ูพุดโุจู ฺฉ ุฌููู ุฌุฏุฏ\n",
    "new_text = [\"ุฎู ูู ุฌุงูุจ ูุจูุฏ\"]\n",
    "new_vec = vectorizer.transform(new_text)\n",
    "prediction = model.predict(new_vec)\n",
    "print(\"๐ ูุชุฌู ุชุญูู ุฌููู:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "๐ ุงูฺฏูุฑุชู: Random Forests (ุฌูฺฏู ุชุตุงุฏู)\n",
    "โ๏ธ ฺุทูุฑ ฺฉุงุฑ ูโฺฉูุฏุ\n",
    "ุงูฺฏูุฑุชู Random Forest ุฏุฑ ูุงูุน ูุฌููุนูโุง ุงุฒ ุฏุฑุฎุชโูุง ุชุตูู (Decision Trees) ูุณุช ฺฉู ุจุง ูู ููฺฉุงุฑ ูโฺฉูู!\n",
    "๐ง ุงุฏูโุงุด ุงูู ฺฉู:\n",
    "\n",
    "ยซุงฺฏู ุงุฒ ฺูุฏู ุฏุฑุฎุช ฺฉู ุจูโุตูุฑุช ุชุตุงุฏู ุขููุฒุด ุฏุฏูโุงู ูุธุฑ ุจฺฏุฑูุ ูุชุฌูโ ููุง ุฏููโุชุฑุ ูพุงุฏุงุฑุชุฑ ู ฺฉูุชุฑ ุฏฺุงุฑ ุงุดุชุจุงู ุฎูุงูุฏ ุจูุฏ.ยป\n",
    "\n",
    "๐ ูุฑุงุญู ฺฉุงุฑ:\n",
    "\n",
    "ฺูุฏู ุฏุฑุฎุช ุชุตูู ุจู ุตูุฑุช ูุณุชูู ุณุงุฎุชู ูโุดู.\n",
    "\n",
    "ูุฑ ุฏุฑุฎุช ููุท ุจุฎุด ุงุฒ ุฏุงุฏูโูุง ุฑู (ุจุง ุฌุงฺฏุฒู) ู ุจุฎุด ุงุฒ ูฺฺฏโูุง ุฑู ูโุจูู โ ุชุตุงุฏู ุจูุฏู\n",
    "\n",
    "ูุฑ ุฏุฑุฎุช ุจู ุชููุง ูพุดโุจู ูโฺฉูู.\n",
    "\n",
    "ุฑุฃโฺฏุฑ (ุจุฑุง Classification) ุง ูุงูฺฏูโฺฏุฑ (ุจุฑุง Regression) ุงูุฌุงู ูโุดู.\n",
    "\n",
    "๐ฏ ฺฉุงุฑุจุฑุฏูุง\n",
    "โ ุชุดุฎุต ุงููโูุง Spam ุง Not Spam\n",
    "โ ุชุญูู ุงุญุณุงุณุงุช (ูุซุจุช / ููู / ุฎูุซ)\n",
    "โ ุชุญูู ูุธุฑุงุช ฺฉุงุฑุจุฑุงู ุฏุฑ ุงูพูฺฉุดูโูุง ุง ูุฑูุดฺฏุงูโูุง\n",
    "โ ุดูุงุณุง ุฑูุชุงุฑ ฺฉุงุฑุจุฑุงู ุฏุฑ ุดุจฺฉูโูุง ุงุฌุชูุงุน\n",
    "โ ุชุดุฎุต ุจูุงุฑโูุง ุฏุฑ ูพุฒุดฺฉ\n",
    "โ ูพุดโุจู ุชููุจโูุง ูุงู\n",
    "โ ูุฏูโูุง ุดูุงุฎุช ุจุฑุง ุชุญูู ูุญู ู ุงุญุณุงุณุงุช ูุงุฎูุฏุขฺฏุงู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ุฏุงุฏูโูุง ููููู (ุฏุงุฑุง ุงุญุณุงุณ ูุณุชูู ู ุบุฑูุณุชูู)\n",
    "texts = [\n",
    "    \"ูุงูุนุง ุนุงู ุจูุฏ\",              # ูุซุจุช\n",
    "    \"ูฺ ููุช ููโุฎุฑู ุฏฺฏู\",        # ููู\n",
    "    \"ูู ุฎูุจ ุจูุฏ ูู ุจุฏ\",           # ุฎูุซ\n",
    "    \"ุฏูุณุด ุฏุงุดุชู\",                  # ูุซุจุช\n",
    "    \"ุจุฏ ูุจูุฏ ูู ุจุงุฒู ููโุฎุฑู\",    # ููู ูพููุงู\n",
    "    \"ูพุดููุงุฏ ููโฺฉูู\",             # ููู\n",
    "    \"ุงุฑุฒุด ุฎุฑุฏ ุฏุงุดุช\",             # ูุซุจุช\n",
    "    \"ูุชูุณุท ุจูุฏ\",                  # ุฎูุซ/ูพููุงู\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"negative\", \"positive\", \"neutral\"]\n",
    "\n",
    "# ูพุฑุฏุงุฒุด ูุชู ุจู ูฺฺฏโูุง ุนุฏุฏ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ุขููุฒุด ูุฏู\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ุงุฑุฒุงุจ\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ูพุดโุจู ุงุญุณุงุณ ูพููุงู ฺฉ ุฌููู\n",
    "sentence = [\"ูู ุฎู ุฎูุจ ุจูุฏ ูู ุฎู ุจุฏ ูู ู ฺุฒ ฺฉู ุฏุงุดุช\"]\n",
    "vector = vectorizer.transform([sentence[0]])\n",
    "prediction = model.predict(vector)\n",
    "print(\"๐ ุงุญุณุงุณ ูพุดโุจูโุดุฏู:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN)\n",
    "ุง ุงูฺฏูุฑุชู k ุชุง ูุฒุฏฺฉโุชุฑู ููุณุงู\n",
    "\n",
    "โ๏ธ ฺุทูุฑ ฺฉุงุฑ ูโฺฉูุฏุ\n",
    "KNN ฺฉ ุงูฺฏูุฑุชู ุณุงุฏู ูู ุจุณุงุฑ ูุคุซุฑ ุฏุฑ ุงุฏฺฏุฑ ูุงุดู (Machine Learning) ุงุณุช ฺฉู ุจุฑ ุงุณุงุณ \"ูุฒุฏฺฉ\" ุชุตูู ูโฺฏุฑุฏ.\n",
    "\n",
    "ูุฑุงุญู ฺฉุงุฑ:\n",
    "ููุช ฺฉ ููููู ุฌุฏุฏ (ูุซูุงู ฺฉ ุฌููู ุง ุชุตูุฑ) ูุงุฑุฏ ูโุดูุ\n",
    "\n",
    "KNN ูุงุฏ ู ุชู ุฏุงุฏูโูุง ุขููุฒุดุ k ุชุง ูุฒุฏฺฉโุชุฑู ููุณุงู ุฑู ุจู ุงูู ููููู ูพุฏุง ูโฺฉูู (ุจุฑ ุงุณุงุณ ูุงุตููโ ุฑุงุถ ูุซู ุงููุฏุณ).\n",
    "\n",
    "ุณูพุณ ุจุฑุฑุณ ูโฺฉูู ฺฉู ุงฺฉุซุฑุช ุงูู k ุชุง ููุณุงู ฺู ุจุฑฺุณุจ ุฏุงุฑูุฏุ\n",
    "\n",
    "ุงฺฏุฑ ุจุดุชุฑุดูู ูุซุจุช ุจูุฏู โ ุฎุฑูุฌ ูู ูุซุจุช ูโุดู\n",
    "\n",
    "ุงฺฏุฑ ููู ุจูุฏู โ ูุชุฌู ููู ูโุดู\n",
    "\n",
    "โ ุงูฺฏูุฑุชู ูฺ ูุฏู ููโุณุงุฒูุ ููุท ุฏุงุฏูโูุง ุฑู ุฐุฎุฑู ูโฺฉูู ู ูููุน ูุงุฒ ุงุฒุดูู ุงุณุชูุงุฏู ูโฺฉูู (ุจูุด ูโฺฏู Lazy Learning).\n",
    "\n",
    "๐ฏ ฺฉุงุฑุจุฑุฏูุง:\n",
    "โ ุชุดุฎุต ุงุญุณุงุณุงุช ุฏุฑ ูุชู (ูุซุจุช / ููู / ุฎูุซ)\n",
    "\n",
    "โ ุฏุณุชูโุจูุฏ ุชุตุงูุฑ (ูุซู ฺฏุฑุจู/ุณฺฏ)\n",
    "\n",
    "โ ุดูุงุณุง ุงููโูุง ุงุณูพู\n",
    "\n",
    "โ ุชุดุฎุต ุจูุงุฑ ุจุฑ ุงุณุงุณ ุนูุงุฆู ูุดุงุจู\n",
    "\n",
    "โ ุชุญูู ฺฏูุชุงุฑ ุงูุฑุงุฏ ุจุฑุง ููู ูุงุฎูุฏุขฺฏุงู (ููุช ุจุงู ุบุฑูุณุชูู ุฏุงุฑู)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ุฏุงุฏูโูุง ุณุงุฏู\n",
    "texts = [\n",
    "    \"ุฎู ุนุงู ุจูุฏ\",          # ูุซุจุช\n",
    "    \"ุงุตูุงู ุฑุงุถ ูุจูุฏู\",       # ููู\n",
    "    \"ูู ุฎู ุจุฏ ุจูุฏ ูู ุฎูุจ\",  # ุฎูุซ\n",
    "    \"ุนุงุดูุด ุดุฏู\",              # ูุซุจุช\n",
    "    \"ุฎุฑุฏ ุจุฏ ุจูุฏ\",           # ููู\n",
    "    \"ูุนููู ุจูุฏ\",             # ุฎูุซ\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# ุชุจุฏู ูุชู ุจู ุจุฑุฏุงุฑ ุนุฏุฏ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ูุฏู ู ุขููุฒุด\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=0)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ุงุฑุฒุงุจ\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ูพุดโุจู ุฌููู ุฌุฏุฏ\n",
    "sentence = [\"ุชุฌุฑุจูโ ุฎูุจ ูุจูุฏ ุฑุงุณุชุด\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "pred = model.predict(vec)\n",
    "print(\"๐ ุงุญุณุงุณ ุดูุงุณุงโุดุฏู:\", pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes (ุจุงุฒ ุณุงุฏู)\n",
    "ุงูฺฏูุฑุชู ุจุฑ ูพุงูโ ุงุญุชูุงูโูุง ฺฉู ุงุฒ ูุงููู ุจุงุฒ ุงุณุชูุงุฏู ูโฺฉูู.\n",
    "\n",
    "โ๏ธ ฺุทูุฑ ฺฉุงุฑ ูโฺฉูุฏุ\n",
    "Naive Bayes ุจุฑ ุงุณุงุณ ูุงููู ุงุญุชูุงู ุจุงุฒ (Bayes' Theorem) ฺฉุงุฑ ูโฺฉูู. ุงู ูุงููู ุจู ูุง ูโฺฏู:\n",
    "\n",
    "ููุช ฺฉ ูฺฺฏ (ูุซู ฺฉููู) ุฏุฏู ุดุฏุ ฺูุฏุฑ ุงุญุชูุงู ุฏุงุฑู ุฌููู ูุชุนูู ุจู ฺฉ ฺฉูุงุณ ุฎุงุต (ูุซูุงู \"ูุซุจุช\" ุง \"ููู\") ุจุงุดูุ\n",
    "\n",
    "๐ ูฺฉุชูโ ุฌุงูุจ:\n",
    "\n",
    "ูุฑุถ ูโฺฉูู ฺฉู ุชูุงู ูฺฺฏโูุง (ฺฉููุงุช) ูุณุชูู ุงุฒ ูู ูุณุชู (ฺฉู ุฏุฑ ูุงูุนุช ููุดู ุฏุฑุณุช ูุณุชุ ูู ุฌูุงุจ ูโุฏู!)\n",
    "\n",
    "ุงู ูุฑุถ ุณุงุฏูโุงูฺฏุงุฑุงูู ุจุงุนุซ ูโุดู ูุฏู ุฎู ุณุฑุน ู ุณุจฺฉ ุจุงุดู.\n",
    "\n",
    "\n",
    "\n",
    "๐ฏ ฺฉุงุฑุจุฑุฏูุง:\n",
    "โ ุชุญูู ุงุญุณุงุณุงุช (Sentiment Analysis)\n",
    "\n",
    "โ ุชุดุฎุต ุงุณูพู ุง ุงูู ุณุงูู\n",
    "\n",
    "โ ุฏุณุชูโุจูุฏ ูุชูู (ุงุฎุจุงุฑุ ูุธุฑุงุชุ ูพุงูโูุง)\n",
    "\n",
    "โ ุชุดุฎุต ุฒุจุงู\n",
    "\n",
    "โ ูพุดโุจู ูุช ูพููุงู ุง ุงุญุณุงุณ ุบุฑูุณุชูู\n",
    "\n",
    "โ ุทุจููโุจูุฏ ุงุณูุงุฏ ุง ุฏุณุชูโุจูุฏ ฺฉุงุฑุจุฑุงู ุจุฑ ุงุณุงุณ ุฑูุชุงุฑ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ุฏุงุฏูโูุง ููููู\n",
    "texts = [\n",
    "    \"ุฎู ุฎูุจ ุจูุฏ\",               # ูุซุจุช\n",
    "    \"ุงูุชุถุงุญ ุจูุฏุ ุงุตูุงู ุฏูุณุช ูุฏุงุดุชู\", # ููู\n",
    "    \"ูู ุจุฏ ุจูุฏ ูู ุฎูุจ\",           # ุฎูุซ\n",
    "    \"ุนุงุดู ุงู ูุญุตูู ุดุฏู\",         # ูุซุจุช\n",
    "    \"ููโุฎุฑู ุฏฺฏู\",               # ููู\n",
    "    \"ูุนููู ุจูุฏ\",                 # ุฎูุซ\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# ุชุจุฏู ูุชู ุจู ุจุฑุฏุงุฑ ุนุฏุฏ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ุขููุฒุด ูุฏู\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=0)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ุงุฑุฒุงุจ\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ูพุดโุจู ฺฉ ุฌูููโ ูพููุงูโุงุญุณุงุณ\n",
    "sentence = [\"ุจุฏ ูุจูุฏ ูู ุญุณ ุฎูุจ ูุฏุงุดุชู\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "prediction = model.predict(vec)\n",
    "print(\"๐ ุงุญุณุงุณ ุดูุงุณุงโุดุฏู:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Gradient Boosting Machines (ูุงุดูโูุง ฺฏุฑุงุฏุงู ุจูุณุชูฺฏ)\n",
    "ฺฏุงู ุจูุด ูโฺฏู: GBM ุง ยซุจูุณุชูฺฏ ุชุฏุฑุฌ ฺฏุฑุงุฏุงูยป\n",
    "โ๏ธ ฺุทูุฑ ฺฉุงุฑ ูโฺฉูุฏุ\n",
    "ุงูฺฏูุฑุชู GBM ฺฉ ุงุฒ ููโุชุฑู ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ูุงุดู (Machine Learning) ุฏุฑ ุฏุณุชูโุจูุฏ ู ุฑฺฏุฑุณููู.\n",
    "ุฑูุด ฺฉุงุฑุด ุจู ุงู ุดฺฉูู:\n",
    "\n",
    "ุงุจุชุฏุง ฺฉ ูุฏู ุถุนู (ูุซู ุฏุฑุฎุช ุชุตูู ฺฉูฺฺฉ) ุณุงุฎุชู ูโุดู.\n",
    "\n",
    "ุณูพุณ ูุฏู ุฏูู ุณุงุฎุชู ูโุดู ุชุง ุงุดุชุจุงูุงุช ูุฏู ูุจู ุฑู ุงุตูุงุญ ฺฉูู.\n",
    "\n",
    "ุงู ูุฑุงูุฏ ุชฺฉุฑุงุฑ ูโุดู ู ุฏุฑ ูุฑ ูุฑุญููุ ูุฏู ุฌุฏุฏ ุชูุงุด ูโฺฉูู ุฎุทุงูุง ูุจู ุฑู ุฌุจุฑุงู ฺฉูู.\n",
    "\n",
    "ุฏุฑ ููุงุชุ ูููโ ูุฏูโูุง ุจุง ูู ุชุฑฺฉุจ ูโุดู ู ฺฉ ูุฏู ูู ูโุณุงุฒู.\n",
    "\n",
    "๐ฑ ยซุจูุณุชูฺฏยป ุนู ุชููุช ุชุฏุฑุฌ.\n",
    "\n",
    "๐ ยซฺฏุฑุงุฏุงูยป ุจู ูุนู ุญุฑฺฉุช ุจู ุณูุช ฺฉุงูุด ุฎุทุงูุง ุจุง ุงุณุชูุงุฏู ุงุฒ ุดุจ (gradient) ุฎุทุงูุงุณุช.\n",
    ":\n",
    "\n",
    "๐ฏ ฺฉุงุฑุจุฑุฏูุง GBM ุฏุฑ ุฏูุง ูุงูุน:\n",
    "ุชุญูู ุงุญุณุงุณุงุช (Sentiment Analysis):\n",
    "GBM ุฎู ุฎูุจ ูโุชููู ุชูุงูุช ุจู ุงุญุณุงุณุงุช ูุซุจุชุ ููู ุง ุญุช ุฎูุซ ุฑู ุชุดุฎุต ุจุฏู. ุจูโุฎุตูุต ุฏุฑ ุฌููุงุช ูพฺุฏู ุง ฺูุฏโูุนูุง ฺฉู ูุฏูโูุง ุณุงุฏูโุชุฑ ููโุชููู ุฏูู ูุถุงูุช ฺฉููุ GBM ุฏุฑุฎุดุงู ุนูู ูโฺฉูู โจ\n",
    "\n",
    "ุชุญูู ูุงุฎูุฏุขฺฏุงู ุฏุฑ ูุชูโูุง:\n",
    "ูุซูุงู ููุช ฺฉุณ ู ูุธุฑ ุบุฑูุณุชูู ุง ุจุง ุทุนูู ูโููุณู (ยซฺู ูุญุตูู ุฎูู ๐ยป)ุ GBM ูโุชููู ุจุง ุชูุฌู ุจู ุงูฺฏููุง ูุจู ูุชูุฌู ุจุดู ฺฉู ุฏุฑ ูุงูุน ุงู ู ูุธุฑ ูููู. ุงู ุนู ูุฏุฑุช ุฏุฑฺฉ ุงุญุณุงุณุงุช ูพููุงู ู ูุญู ูุชู ๐\n",
    "\n",
    "ุชุดุฎุต ุงุณูพู:\n",
    "ุชู ุงููโูุง ุง ูพุงูโูุงุ GBM ูโุชููู ุงุณูพูโูุง ฺฉู ุฎู ุญุฑููโุง ู ุดุจู ูพุงูโูุง ุนุงุฏ ููุดุชู ุดุฏู ุฑู ูู ุชุดุฎุต ุจุฏู. ฺูู ุงุฏ ูโฺฏุฑู ฺฉู ุงูฺฏููุง ุงุณูพู ุญุช ุงฺฏู ูุณุชูู ูุจุงุดูุ ูุนูููุงู ูุดูููโูุง ุฏุงุฑู.\n",
    "\n",
    "ุณุณุชูโูุง ูพุดููุงุฏุฏููุฏู (Recommendation Systems):\n",
    "ูุซูุงู ููุช GBM ุฑู ุงุทูุงุนุงุช ุฎุฑุฏ ูุจู ู ูุงฺฉูุดโูุง ฺฉุงุฑุจุฑุงู ุขููุฒุด ุฏุงุฏู ุจุดูุ ูโุชููู ุฎู ุฏูู ุจูุดูู ูููุ ฺฉุชุงุจ ุง ูุญุตูู ููุงุณุจ ูพุดููุงุฏ ุจุฏู.\n",
    "\n",
    "ูพุดโุจู ุฑูุชุงุฑ ฺฉุงุฑุจุฑ:\n",
    "GBM ูโุชููู ุจุฑ ุงุณุงุณ ุญุฑฺฉุงุช ูุจู ฺฉุงุฑุจุฑ (ูุซู ฺฉูฺฉโูุงุ ุชุงูพโูุงุ ุงูุชุฎุงุจโูุง) ุงุญุณุงุณุงุช ุง ุชุตููโูุง ุขูุฏูโุด ุฑู ูพุดโุจู ฺฉููุ ุญุช ุงฺฏุฑ ุฎูุฏุด ุฏูู ูุฏููู ฺุฑุง ุงูู ุชุตููู ฺฏุฑูุชู (ุนู ูุงุฎูุฏุขฺฏุงูุด ุฏุฎู ุจูุฏู) ๐ง\n",
    "\n",
    "ูพุดโุจู ุฏุฑ ุจุงุฒุงุฑูุง ูุงู:\n",
    "ุฏุฑ ุชุญูู ุฏุงุฏูโูุง ูุงู ฺฉู ูพุฑ ุงุฒ ููุณุงูุงุช ู ุนูุงูู ูพููุงููุ GBM ูโุชููู ุฑุงุจุทูโูุง ุบุฑุฎุท ุจู ูพุงุฑุงูุชุฑูุง ุฑู ุดูุงุณุง ฺฉูู ู ุขูุฏู ููุชโูุง ุง ุฑุณฺฉโูุง ุฑู ูพุดโุจู ฺฉูู ๐๐\n",
    "\n",
    "ูพุฒุดฺฉ ู ุณูุงูุช ุฑูุงู:\n",
    "GBM ุจุฑุง ุชุญูู ฺฏุฒุงุฑุดโูุง ูพุฒุดฺฉุ ุนูุงุฆู ุจูุงุฑุงูุ ุง ุญุช ุงุฏุฏุงุดุชโูุง ุฑูุงูโุดูุงุณุงู ูโุชููู ุงูฺฏููุง ููู ู ูพููุงู ุฑู ฺฉุดู ฺฉูู. ุงู ุฎู ฺฉุงุฑุจุฑุฏู ุฏุฑ ุชุดุฎุต ุฒูุฏููฺฏุงู ุจูุงุฑโูุง ุง ุงูุณุฑุฏฺฏ ุงุฒ ุฑู ูุชู ฺฏูุชโูฺฏููุง.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ุฏุงุฏูโูุง ููููู\n",
    "texts = [\n",
    "    \"ุฎู ุฎูุดู ุงููุฏ\",        # ูุซุจุช\n",
    "    \"ุงูุชุถุงุญ ุจูุฏ\",             # ููู\n",
    "    \"ูู ุฎูุจ ุจูุฏ ูู ุจุฏ\",      # ุฎูุซ\n",
    "    \"ุนุงุดู ุงู ูุญุตูู ุดุฏู\",     # ูุซุจุช\n",
    "    \"ูุงูุนุง ูพุดูููู\",          # ููู\n",
    "    \"ูุนููู ุจูุฏ\",            # ุฎูุซ\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# ุจุฑุฏุงุฑุณุงุฒ ูุชู\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ุขููุฒุด ูุฏู\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# ุงุฑุฒุงุจ\n",
    "y_pred = model.predict(X_test.toarray())\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ูพุดโุจู ฺฉ ุฌูููโ ุงุญุณุงุณโูพููุงู\n",
    "sentence = [\"ูุซูุงู ฺุฒ ุฎูุจ ุจูุฏ\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "prediction = model.predict(vec.toarray())\n",
    "print(\"๐ ุงุญุณุงุณ ุดูุงุณุงโุดุฏู:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Logistic Regression\n",
    "(ุฑฺฏุฑุณูู ูุฌุณุชฺฉ)\n",
    "\n",
    "โ๏ธ ฺุทูุฑ ฺฉุงุฑ ูโฺฉูุฏุ\n",
    "ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจุฑุฎูุงู ุงุณูุดุ ุจุฑุง ุทุจููโุจูุฏ (Classification) ุงุณุชูุงุฏู ูโุดูุ ูู ุฑฺฏุฑุณูู ูุงูุน!\n",
    "ูุฏูุด ุงูู ฺฉู ุงุญุชูุงู ุชุนูู ฺฉ ูุฑูุฏ ุจู ฺฉ ฺฉูุงุณ ุฎุงุต ุฑู ุญุณุงุจ ฺฉููุ ูุซูุงู:\n",
    "\n",
    "ยซุงู ุฌููู ุงุญุชูุงูุงู นฐูช ุงุญุณุงุณ ูุซุจุชู ู ฑฐูช ููู.ยป\n",
    "\n",
    "ูุฑูููุด ู ุชุงุจุน ุจู ุงุณู ุณฺฏููุฏ (Sigmoid) ุฏุงุฑู ฺฉู ุฎุฑูุฌ ุจู ฐ ู ฑ ุชููุฏ ูโฺฉูู. ุงู ููุฏุงุฑุ ูููู ุงุญุชูุงู ุชุนูู ุจู ฺฉ ฺฉูุงุณ ุฎุงุตู.\n",
    "\n",
    "๐ ฺฉุงุฑุจุฑุฏูุง:\n",
    "ุชุญูู ุงุญุณุงุณุงุช (Sentiment Analysis):\n",
    "ุฎู ูพุฑฺฉุงุฑุจุฑุฏู ุจุฑุง ุชุดุฎุต ูุซุจุช ุง ููู ุจูุฏู ูุธุฑุงุชุ ุชูุชโูุงุ ูพุงูโูุง ู ููุฏูุง.\n",
    "\n",
    "ุชุดุฎุต ุงุณูพู:\n",
    "ุงูู ุง ูพุงู ุฑู ูโฺฏุฑู ู ุงุญุชูุงู ุงุณูพู ุจูุฏูุด ุฑู ูพุดโุจู ูโฺฉูู.\n",
    "\n",
    "ุชุญูู ูุงุฎูุฏุขฺฏุงู ู ูุญู:\n",
    "ูโุชููู ุจุฑ ุงุณุงุณ ุงูุชุฎุงุจ ฺฉููุงุช ู ูุญูู ุจุงูุ ุงุญุณุงุณ ูุงูุน ูพุดุช ุฌููู ุฑู ุญุฏุณ ุจุฒูู.\n",
    "\n",
    "ุชุดุฎุต ุจูุงุฑ ุงุฒ ุฑู ุฏุงุฏูโูุง ูพุฒุดฺฉ ูุชู ุง ุนุฏุฏ:\n",
    "ูุซูุงู ุขุง ูุฑุฏ ุงุญุชูุงู ุฏุงุฑู ุงูุณุฑุฏู ุจุงุดู ุง ูู.\n",
    "\n",
    "ูพุดโุจู ูุฑุฎ ุฑุฒุด ฺฉุงุฑุจุฑุงู (Churn Prediction):\n",
    "ุขุง ุงู ฺฉุงุฑุจุฑ ุงูพูฺฉุดู ุง ุณุงุช ุฑู ุชุฑฺฉ ูโฺฉูู ุง ููุ\n",
    "\n",
    "ุชุดุฎุต ุชููุจ (Fraud Detection):\n",
    "ุฑู ุชุฑุงฺฉูุดโูุง ุจุงูฺฉ ุง ุฎุฑุฏูุง ฺฉุงุฑ ูโฺฉูู ู ุงุญุชูุงู ุชููุจ ุฑู ูโุณูุฌู.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ุฏุงุฏูโูุง ุขููุฒุด\n",
    "texts = [\"I love this!\", \"This is bad\", \"What a great movie\", \"Horrible experience\"]\n",
    "labels = [1, 0, 1, 0]  # 1 = ูุซุจุชุ 0 = ููู\n",
    "\n",
    "# ุชุจุฏู ูุชู ุจู ูฺฺฏ ุนุฏุฏ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ุขููุฒุด ูุฏู\n",
    "model = LogisticRegression()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# ุชุณุช\n",
    "test_text = [\"I hate this movie\"]\n",
    "test_vec = vectorizer.transform(test_text)\n",
    "prediction = model.predict(test_vec)\n",
    "\n",
    "print(\"Prediction:\", \"ูุซุจุช\" if prediction[0] == 1 else \"ููู\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
