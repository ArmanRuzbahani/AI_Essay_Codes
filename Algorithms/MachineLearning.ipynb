{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ø³ÙØ± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ: Ø¢Ø´Ù†Ø§ÛŒÛŒ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… SVM ğŸš€ğŸ“Š\n",
    "\n",
    "**Ø¨ÛŒØ§ÛŒÛŒØ¯ ÛŒÚ©ÛŒ Ø§Ø² Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø±Ø§ Ú©Ø´Ù Ú©Ù†ÛŒÙ…:**\n",
    "\n",
    "## <span style=\"color:#8e24aa;\">SVM (Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†)</span> ğŸ§­  \n",
    "- **Ù…Ø±Ø² Ø¯Ù‚ÛŒÙ‚ Ø¨ÛŒÙ† Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§** âœ‚ï¸  \n",
    "- Ø¨Ù‡â€ŒØ¯Ù†Ø¨Ø§Ù„ ÛŒØ§ÙØªÙ† ÛŒÚ© Ø§Ø¨Ø±ØµÙØ­Ù‡ (Hyperplane) Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† ØªÙÚ©ÛŒÚ© Ø¨ÛŒÙ† Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯  \n",
    "- Ù†Ù‚Ø§Ø· Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ù…Ø±Ø² ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ù‡ Ù†Ø§Ù… <span style=\"color:#ff9800;\">Support Vectors</span> Ø´Ù†Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯  \n",
    "- Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ø§Ø¨Ø¹Ø§Ø¯ Ø²ÛŒØ§Ø¯ (High Dimensional) Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©  \n",
    "\n",
    "## ğŸ› ï¸ Ú†Ø·ÙˆØ± Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ\n",
    "- Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± ÙØ¶Ø§ÛŒ nâ€ŒØ¨Ø¹Ø¯ÛŒ Ù†Ú¯Ø§Ø´Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯  \n",
    "- Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø±Ø§ **Ù…Ø§Ú©Ø²ÛŒÙ…Ù…** Ú©Ù†Ø¯  \n",
    "- Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§ Ù‡Ø³ØªÙ‡â€ŒÙ‡Ø§ (Kernels) Ù…Ø±Ø²Ù‡Ø§ÛŒ ØºÛŒØ±Ø®Ø·ÛŒ Ù‡Ù… Ø¨Ø³Ø§Ø²Ø¯!\n",
    "\n",
    "## ğŸ§  Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§:\n",
    "- ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡ ğŸ‘¤  \n",
    "- Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ (Spam vs Ham) ğŸ“¬  \n",
    "- Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú˜Ù†ØªÛŒÚ©ÛŒ ğŸ§¬  \n",
    "\n",
    "ğŸ“Œ **Ù†Ú©ØªÙ‡ Ø·Ù„Ø§ÛŒÛŒ:**  \n",
    "Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¬Ø¯Ø§Ù¾Ø°ÛŒØ± Ù†ÛŒØ³ØªÙ†Ø¯ØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **Ù‡Ø³ØªÙ‡â€ŒÙ‡Ø§ (Kernel Trick)** Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ÙØ¶Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ù…ÛŒâ€ŒØ¨Ø±Ø¯ Ú©Ù‡ Ø¯Ø± Ø¢Ù†Ø¬Ø§ Ø¬Ø¯Ø§Ù¾Ø°ÛŒØ± Ø¨Ø§Ø´Ù†Ø¯!\n",
    "\n",
    "ğŸ¯ **Ù‡Ø¯Ù Ù…Ø§ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø³ÛŒØ±:**  \n",
    "Ø¯Ø±Ú© Ø´Ù‡ÙˆØ¯ÛŒ Ø§Ø² Ù…Ø±Ø² ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ + Ø¢Ø´Ù†Ø§ÛŒÛŒ Ø¨Ø§ Support Vectors + ØªÙ…Ø±ÛŒÙ† Ø¹Ù…Ù„ÛŒ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# ğŸ“ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ø¨Ø±Ú†Ø³Ø¨ Ø§Ø­Ø³Ø§Ø³Ø§Øª (0 = Ù…Ù†ÙÛŒØŒ 1 = Ù…Ø«Ø¨Øª)\n",
    "texts = [\n",
    "    \"Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯ Ùˆ Ø®ÛŒÙ„ÛŒ Ø¯ÙˆØ³ØªØ´ Ø¯Ø§Ø´ØªÙ…\",\n",
    "    \"ÙˆØ§Ù‚Ø¹Ø§ Ø§ÙØªØ¶Ø§Ø­ Ø¨ÙˆØ¯ØŒ ÙˆÙ‚Øª ØªÙ„Ù Ú©Ø±Ø¯Ù† Ø¨ÙˆØ¯\",\n",
    "    \"Ø¨Ø§Ø²ÛŒÚ¯Ø±Ù‡Ø§ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ùˆ Ø¯Ø§Ø³ØªØ§Ù† Ø¬Ø°Ø§Ø¨ Ø¨ÙˆØ¯\",\n",
    "    \"Ú©Ø³Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ùˆ Ø¨ÛŒâ€ŒÙ…Ø­ØªÙˆØ§ØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ù…\",\n",
    "    \"ÛŒÚ©ÛŒ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯ÛŒØ¯Ù…\",\n",
    "    \"Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ Ø¨ÙˆØ¯ØŒ Ø§ØµÙ„Ø§Ù‹ Ø®ÙˆØ´Ù… Ù†ÛŒÙˆÙ…Ø¯\"\n",
    "]\n",
    "labels = [1, 0, 1, 0, 1, 0]  # Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§\n",
    "\n",
    "# ğŸ”§ Ø³Ø§Ø®Øª pipeline: ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± + Ù…Ø¯Ù„ SVM Ø®Ø·ÛŒ\n",
    "model = make_pipeline(TfidfVectorizer(), LinearSVC())\n",
    "\n",
    "# ğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
    "model.fit(texts, labels)\n",
    "\n",
    "# ğŸ§ª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­Ø³Ø§Ø³ Ø¬Ù…Ù„Ù‡â€ŒÛŒ Ø¬Ø¯ÛŒØ¯\n",
    "new_text = \"ÙÛŒÙ„Ù… Ø®ÛŒÙ„ÛŒ Ù‚Ø´Ù†Ú¯ Ùˆ Ø§Ù„Ù‡Ø§Ù…â€ŒØ¨Ø®Ø´ Ø¨ÙˆØ¯\"\n",
    "prediction = model.predict([new_text])\n",
    "\n",
    "print(\"ğŸŒŸ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª:\", \"Ù…Ø«Ø¨Øª\" if prediction[0] == 1 else \"Ù…Ù†ÙÛŒ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ³ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… (Decision Tree)\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Ú†Ú¯ÙˆÙ†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ\n",
    "\n",
    "Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ø´Ø¨ÛŒÙ‡ ÛŒÚ© Ø¯Ø±Ø®Øª Ù…Ù†Ø·Ù‚ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ø¢Ù† Ù‡Ø± **Ú¯Ø±Ù‡ (Node)** ÛŒÚ© Ø³Ø¤Ø§Ù„ Ù…ÛŒâ€ŒÙ¾Ø±Ø³Ø¯ Ùˆ Ø¨Ø±Ø§Ø³Ø§Ø³ Ù¾Ø§Ø³Ø® (Ù…Ø«Ù„Ø§Ù‹ Â«Ø¨Ù„Ù‡Â» ÛŒØ§ Â«Ø®ÛŒØ±Â») Ø¨Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø´Ø§Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ù…ÛŒâ€ŒØ±ÙˆÛŒÙ….  \n",
    "Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ø¨Ù‡ **Ø¨Ø±Ú¯ (Leaf)** Ù…ÛŒâ€ŒØ±Ø³ÛŒÙ… Ú©Ù‡ Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ (Ù…Ø«Ù„Ø§Ù‹ Â«Ø§ÛŒÙ…ÛŒÙ„ Ø§Ø³Ù¾Ù… Ø§Ø³ØªÂ» ÛŒØ§ Â«Ù†ÛŒØ³ØªÂ») Ø±Ø§ ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§ØµÙ„ÛŒ\n",
    "\n",
    "1. **Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§** Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒ (feature) Ø¬Ù‡Øª ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§.\n",
    "2. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯:\n",
    "    - Information Gain\n",
    "    - Gini Index\n",
    "3. Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ø¯Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "4. Ø§ÛŒÙ† Ø±ÙˆÙ†Ø¯ **Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ** ØªÚ©Ø±Ø§Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§:\n",
    "    - Ù‡Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡â€ŒØ®ÙˆØ¨ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´ÙˆÙ†Ø¯ØŒ\n",
    "    - ÛŒØ§ Ø¨Ù‡ Ø¹Ù…Ù‚ Ù…Ø´Ø®ØµÛŒ Ø§Ø² Ø¯Ø±Ø®Øª Ø¨Ø±Ø³ÛŒÙ….\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù…\n",
    "\n",
    "- âœ… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ù¾Ù… ÛŒØ§ ØºÛŒØ± Ø§Ø³Ù¾Ù…\n",
    "- âœ… ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¯Ø± Ù…ØªÙˆÙ† (Ù…Ø«Ø¨Øª / Ù…Ù†ÙÛŒ / Ø®Ù†Ø«ÛŒ)\n",
    "- âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø²Ø´Ú©ÛŒ\n",
    "- âœ… Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø¹ØªØ¨Ø§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø± Ø§Ù…ÙˆØ± Ø¨Ø§Ù†Ú©ÛŒ\n",
    "- âœ… ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒÚ¯Ø± (Recommendation Systems)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± ÛŒÚ© Ø¬Ù…Ù„Ù‡:\n",
    "\n",
    "> **Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Ù¾Ø±Ø³Ø´â€ŒÙ‡Ø§ÛŒ Ù…ØªÙˆØ§Ù„ÛŒ ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ø¨Ø§ Ù…Ù†Ø·Ù‚ Ø³Ø§Ø¯Ù‡ Ùˆ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù…ØŒ Ø¨Ù‡ØªØ±ÛŒÙ† ØªØµÙ…ÛŒÙ… ÛŒØ§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ğŸ“ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø­Ø³Ø§Ø³ Ù¾Ù†Ù‡Ø§Ù† Ù‡Ù… Ø¯Ø§Ø±Ù†)\n",
    "texts = [\n",
    "    \"Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯\",         # Ù…Ø«Ø¨Øª\n",
    "    \"Ø§ÙØªØ¶Ø§Ø­Ù‡ØŒ Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª Ù†Ù…ÛŒâ€ŒØ®Ø±Ù…\",    # Ù…Ù†ÙÛŒ\n",
    "    \"Ù…ÛŒâ€ŒØªÙˆÙ†Ø³Øª Ø¨Ù‡ØªØ± Ø¨Ø§Ø´Ù‡\",          # Ù…Ù†ÙÛŒÙ Ù…Ù„Ø§ÛŒÙ… (Ù†Ø´ÙˆÙ†Ù‡ Ù†Ø§Ø±Ø¶Ø§ÛŒØªÛŒ Ù†Ø§Ø®ÙˆØ¯Ø¢Ú¯Ø§Ù‡)\n",
    "    \"ÙˆØ§Ù‚Ø¹Ø§ Ø¯ÙˆØ³ØªØ´ Ø¯Ø§Ø´ØªÙ…\",          # Ù…Ø«Ø¨Øª\n",
    "    \"Ù†Ù‡ Ø¨Ø¯ Ø¨ÙˆØ¯ Ù†Ù‡ Ø®ÙˆØ¨\",           # Ø®Ù†Ø«ÛŒ\n",
    "    \"Ø¨Ø¯ Ù†Ø¨ÙˆØ¯ ÙˆÙ„ÛŒ Ø¹Ø§Ù„ÛŒ Ù‡Ù… Ù†Ø¨ÙˆØ¯\",   # Ø®Ù†Ø«ÛŒ / Ù…Ù†ÙÛŒ Ù…Ù„Ø§ÛŒÙ…\n",
    "    \"ÛŒÚ©ÛŒ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† ØªØ¬Ø±Ø¨Ù‡â€ŒÙ‡Ø§Ù… Ø¨ÙˆØ¯\", # Ù…Ø«Ø¨Øª\n",
    "    \"Ø¨ÛŒâ€ŒÙ†Ø¸Ø± Ø¨ÙˆØ¯ØŒ Ø§Ù„Ø¨ØªÙ‡ Ø§Ú¯Ù‡ Ù…Ø´Ú©Ù„Ø´ Ù†Ø¨ÙˆØ¯\", # Ø§Ø­Ø³Ø§Ø³ÛŒ Ø¯ÙˆÚ¯Ø§Ù†Ù‡ (Ù…Ø®Ù„ÙˆØ·)\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"negative\", \"positive\", \"neutral\", \"neutral\", \"positive\", \"negative\"]\n",
    "\n",
    "# ğŸ”¤ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¹Ø¯Ø¯ÛŒ (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# ğŸ¯ Ù…Ø¯Ù„ Ùˆ Ø¢Ù…ÙˆØ²Ø´\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ğŸ“ˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ğŸ” Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¬Ø¯ÛŒØ¯\n",
    "new_text = [\"Ø®ÛŒÙ„ÛŒ Ù‡Ù… Ø¬Ø§Ù„Ø¨ Ù†Ø¨ÙˆØ¯\"]\n",
    "new_vec = vectorizer.transform(new_text)\n",
    "prediction = model.predict(new_vec)\n",
    "print(\"ğŸŒŸ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¬Ù…Ù„Ù‡:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸƒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…: Random Forests (Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒ)\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Ú†Ú¯ÙˆÙ†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ\n",
    "\n",
    "Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… **Random Forest** Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ§ÛŒ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† **Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…** (Decision Trees) Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ú¯Ø±ÙˆÙ‡ÛŒ Ø¨Ø§ Ù‡Ù… Ù‡Ù…Ú©Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯!\n",
    "\n",
    "ğŸ§  **Ø§ÛŒØ¯Ù‡ Ø§ØµÙ„ÛŒ:**  \n",
    "Ø§Ú¯Ø± Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ø¯Ø±Ø®Øª Ú©Ù‡ Ù‡Ø±Ú©Ø¯Ø§Ù… Ø¨Ù‡â€ŒØµÙˆØ±Øª ØªØµØ§Ø¯ÙÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡â€ŒØ§Ù†Ø¯ Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒÙ…ØŒ  \n",
    "Ù†ØªÛŒØ¬Ù‡â€ŒÛŒ Ù†Ù‡Ø§ÛŒÛŒ **Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ØªØ±** Ùˆ **Ú©Ù…â€ŒØ®Ø·Ø§ØªØ±** Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Ù…Ø±Ø§Ø­Ù„ Ø§Ø¬Ø±Ø§\n",
    "\n",
    "1. **Ø³Ø§Ø®Øª Ú†Ù†Ø¯ÛŒÙ† Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…** Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù…Ø³ØªÙ‚Ù„.\n",
    "2. Ù‡Ø± Ø¯Ø±Ø®Øª ÙÙ‚Ø· **Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§** Ø±Ø§ (Ø¨Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ) Ùˆ **Ø¨Ø®Ø´ÛŒ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§** Ø±Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ø¯ â†’ Ø§ÛŒØ¬Ø§Ø¯ ØªØµØ§Ø¯ÙÛŒ Ø¨ÙˆØ¯Ù† (Randomness).\n",
    "3. Ù‡Ø± Ø¯Ø±Ø®Øª Ø¨Ù‡â€ŒØªÙ†Ù‡Ø§ÛŒÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "4. **Ø±Ø£ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ** (Ø¯Ø± Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ/Classification) ÛŒØ§ **Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ** (Ø¯Ø± Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†/Regression) Ø±ÙˆÛŒ Ù†ØªØ§ÛŒØ¬ Ù‡Ù…Ù‡ Ø¯Ø±Ø®Øªâ€ŒÙ‡Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù…\n",
    "\n",
    "- âœ… ØªØ´Ø®ÛŒØµ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Spam ÛŒØ§ Not Spam\n",
    "- âœ… ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª (Ù…Ø«Ø¨Øª / Ù…Ù†ÙÛŒ / Ø®Ù†Ø«ÛŒ)\n",
    "- âœ… ØªØ­Ù„ÛŒÙ„ Ù†Ø¸Ø±Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¯Ø± Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†â€ŒÙ‡Ø§ ÛŒØ§ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§\n",
    "- âœ… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±ÙØªØ§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¯Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ\n",
    "- âœ… ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ù¾Ø²Ø´Ú©ÛŒ\n",
    "- âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªÙ‚Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ\n",
    "- âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù„Ø­Ù† Ùˆ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù†Ø§Ø®ÙˆØ¯Ø¢Ú¯Ø§Ù‡\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± ÛŒÚ© Ø¬Ù…Ù„Ù‡:\n",
    "\n",
    "> **Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒØŒ Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ Ú†Ù†Ø¯ÛŒÙ† Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… ØªØµØ§Ø¯ÙÛŒØŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ù‚ÙˆÛŒØŒ Ù¾Ø§ÛŒØ¯Ø§Ø± Ùˆ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªÚ©ÛŒ Ú©Ù…ØªØ± Ø¯Ú†Ø§Ø± Ø®Ø·Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ (Ø¯Ø§Ø±Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³ Ù…Ø³ØªÙ‚ÛŒÙ… Ùˆ ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ…)\n",
    "texts = [\n",
    "    \"ÙˆØ§Ù‚Ø¹Ø§ Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯\",              # Ù…Ø«Ø¨Øª\n",
    "    \"Ù‡ÛŒÚ† ÙˆÙ‚Øª Ù†Ù…ÛŒâ€ŒØ®Ø±Ù… Ø¯ÛŒÚ¯Ù‡\",        # Ù…Ù†ÙÛŒ\n",
    "    \"Ù†Ù‡ Ø®ÙˆØ¨ Ø¨ÙˆØ¯ Ù†Ù‡ Ø¨Ø¯\",           # Ø®Ù†Ø«ÛŒ\n",
    "    \"Ø¯ÙˆØ³Ø´ Ø¯Ø§Ø´ØªÙ…\",                  # Ù…Ø«Ø¨Øª\n",
    "    \"Ø¨Ø¯ Ù†Ø¨ÙˆØ¯ ÙˆÙ„ÛŒ Ø¨Ø§Ø²Ù… Ù†Ù…ÛŒâ€ŒØ®Ø±Ù…\",    # Ù…Ù†ÙÛŒ Ù¾Ù†Ù‡Ø§Ù†\n",
    "    \"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ù…\",             # Ù…Ù†ÙÛŒ\n",
    "    \"Ø§Ø±Ø²Ø´ Ø®Ø±ÛŒØ¯ Ø¯Ø§Ø´Øª\",             # Ù…Ø«Ø¨Øª\n",
    "    \"Ù…ØªÙˆØ³Ø· Ø¨ÙˆØ¯\",                  # Ø®Ù†Ø«ÛŒ/Ù¾Ù†Ù‡Ø§Ù†\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"negative\", \"positive\", \"neutral\"]\n",
    "\n",
    "# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­Ø³Ø§Ø³ Ù¾Ù†Ù‡Ø§Ù† ÛŒÚ© Ø¬Ù…Ù„Ù‡\n",
    "sentence = [\"Ù†Ù‡ Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ¨ Ø¨ÙˆØ¯ Ù†Ù‡ Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ ÙˆÙ„ÛŒ ÛŒÙ‡ Ú†ÛŒØ²ÛŒ Ú©Ù… Ø¯Ø§Ø´Øª\"]\n",
    "vector = vectorizer.transform([sentence[0]])\n",
    "prediction = model.predict(vector)\n",
    "print(\"ğŸ” Ø§Ø­Ø³Ø§Ø³ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‘¥ K-Nearest Neighbors (KNN)  \n",
    "### ÛŒØ§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… k ØªØ§ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù‡Ù…Ø³Ø§ÛŒÙ‡\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Ú†Ú¯ÙˆÙ†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ\n",
    "\n",
    "**KNN** ÛŒÚ©ÛŒ Ø§Ø² Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ùˆ Ø¯Ø± Ø¹ÛŒÙ† Ø­Ø§Ù„ Ù…Ø¤Ø«Ø±ØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ø¨Ø± Ù¾Ø§ÛŒÙ‡â€ŒÛŒ \"Ù†Ø²Ø¯ÛŒÚ©ÛŒ\" ÛŒØ§ Ø´Ø¨Ø§Ù‡Øª Ø¨ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.\n",
    "\n",
    "---\n",
    "\n",
    "### Ù…Ø±Ø§Ø­Ù„ Ø§Ø¬Ø±Ø§\n",
    "\n",
    "1. **ÙˆØ±ÙˆØ¯ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø¬Ø¯ÛŒØ¯** (Ù…Ø«Ù„Ø§Ù‹ ÛŒÚ© Ø¬Ù…Ù„Ù‡ ÛŒØ§ ØªØµÙˆÛŒØ±)\n",
    "2. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† **k ØªØ§ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù‡Ù…Ø³Ø§ÛŒÙ‡** Ø¨Ù‡ Ø¢Ù† Ù†Ù…ÙˆÙ†Ù‡ (Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¹ÛŒØ§Ø± ÙØ§ØµÙ„Ù‡ØŒ Ù…Ø«Ù„ ÙØ§ØµÙ„Ù‡ Ø§Ù‚Ù„ÛŒØ¯Ø³ÛŒ)\n",
    "3. Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ú†Ø³Ø¨ Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§:\n",
    "    - Ø§Ú¯Ø± Ø§Ú©Ø«Ø±ÛŒØª **Ù…Ø«Ø¨Øª** Ø¨Ø§Ø´Ù†Ø¯ â†’ Ù†ØªÛŒØ¬Ù‡ Ù…Ø«Ø¨Øª Ø§Ø³Øª.\n",
    "    - Ø§Ú¯Ø± Ø§Ú©Ø«Ø±ÛŒØª **Ù…Ù†ÙÛŒ** Ø¨Ø§Ø´Ù†Ø¯ â†’ Ù†ØªÛŒØ¬Ù‡ Ù…Ù†ÙÛŒ Ø§Ø³Øª.\n",
    "\n",
    "> **KNN Ù‡ÛŒÚ† Ù…Ø¯Ù„ÛŒ Ù†Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯Ø› ÙÙ‚Ø· Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù‡Ù†Ú¯Ø§Ù… Ù†ÛŒØ§Ø² Ø§Ø² Ø¢Ù†â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ù‡ Ø§ÛŒÙ† Ù†ÙˆØ¹ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ Lazy Learning Ú¯ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ KNN\n",
    "\n",
    "- âœ… ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¯Ø± Ù…ØªÙ† (Ù…Ø«Ø¨Øª / Ù…Ù†ÙÛŒ / Ø®Ù†Ø«ÛŒ)\n",
    "- âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ØªØµØ§ÙˆÛŒØ± (Ù…Ø«Ù„ Ú¯Ø±Ø¨Ù‡/Ø³Ú¯)\n",
    "- âœ… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ù¾Ù…\n",
    "- âœ… ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù„Ø§Ø¦Ù… Ù…Ø´Ø§Ø¨Ù‡\n",
    "- âœ… ØªØ­Ù„ÛŒÙ„ Ú¯ÙØªØ§Ø± Ø§ÙØ±Ø§Ø¯ Ø¨Ø±Ø§ÛŒ ÙÙ‡Ù… Ù†Ø§Ø®ÙˆØ¯Ø¢Ú¯Ø§Ù‡ (Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ ÙˆÙ‚ØªÛŒ Ø¨ÛŒØ§Ù† ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø§Ø±Ù†Ø¯)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± ÛŒÚ© Ø¬Ù…Ù„Ù‡:\n",
    "\n",
    "> **KNNØŒ Ø¨Ø¯ÙˆÙ† Ø³Ø§Ø®ØªÙ† Ù…Ø¯Ù„ØŒ Ø¨Ø§ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒÛŒ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒØŒ ØªØµÙ…ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡\n",
    "texts = [\n",
    "    \"Ø®ÛŒÙ„ÛŒ Ø¹Ø§Ù„ÛŒ Ø¨ÙˆØ¯\",          # Ù…Ø«Ø¨Øª\n",
    "    \"Ø§ØµÙ„Ø§Ù‹ Ø±Ø§Ø¶ÛŒ Ù†Ø¨ÙˆØ¯Ù…\",       # Ù…Ù†ÙÛŒ\n",
    "    \"Ù†Ù‡ Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ Ø¨ÙˆØ¯ Ù†Ù‡ Ø®ÙˆØ¨\",  # Ø®Ù†Ø«ÛŒ\n",
    "    \"Ø¹Ø§Ø´Ù‚Ø´ Ø´Ø¯Ù…\",              # Ù…Ø«Ø¨Øª\n",
    "    \"Ø®Ø±ÛŒØ¯ Ø¨Ø¯ÛŒ Ø¨ÙˆØ¯\",           # Ù…Ù†ÙÛŒ\n",
    "    \"Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨ÙˆØ¯\",             # Ø®Ù†Ø«ÛŒ\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Ù…Ø¯Ù„ Ùˆ Ø¢Ù…ÙˆØ²Ø´\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=0)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¬Ù…Ù„Ù‡ Ø¬Ø¯ÛŒØ¯\n",
    "sentence = [\"ØªØ¬Ø±Ø¨Ù‡â€ŒÛŒ Ø®ÙˆØ¨ÛŒ Ù†Ø¨ÙˆØ¯ Ø±Ø§Ø³ØªØ´\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "pred = model.predict(vec)\n",
    "print(\"ğŸ” Ø§Ø­Ø³Ø§Ø³ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡:\", pred[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Naive Bayes (Ø¨Ø§ÛŒØ² Ø³Ø§Ø¯Ù‡)\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Ú†Ú¯ÙˆÙ†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ\n",
    "\n",
    "**Naive Bayes** ÛŒÚ© Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³Øª Ú©Ù‡ Ø§Ø² **Ù‚Ø§Ù†ÙˆÙ† Ø¨Ø§ÛŒØ² (Bayes' Theorem)** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.  \n",
    "Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ø¨Ù‡ Ù…Ø§ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯:  \n",
    "ÙˆÙ‚ØªÛŒ ÛŒÚ© ÙˆÛŒÚ˜Ú¯ÛŒ (Ù…Ø«Ù„Ø§Ù‹ ÛŒÚ© Ú©Ù„Ù…Ù‡) Ø¯ÛŒØ¯Ù‡ Ø´Ø¯ØŒ Ú†Ù‚Ø¯Ø± Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø§Ø±Ø¯ Ø¬Ù…Ù„Ù‡ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡ ÛŒÚ© Ú©Ù„Ø§Ø³ Ø®Ø§Øµ Ø¨Ø§Ø´Ø¯ (Ù…Ø«Ù„Ø§Ù‹ Â«Ù…Ø«Ø¨ØªÂ» ÛŒØ§ Â«Ù…Ù†ÙÛŒÂ»).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” Ù†Ú©ØªÙ‡ Ø¬Ø§Ù„Ø¨\n",
    "\n",
    "- **ÙØ±Ø¶ Ù…Ù‡Ù…:** Ù‡Ù…Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ Ú©Ù„Ù…Ø§Øª) Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ø³ØªÙ‚Ù„ Ø§Ø² Ù‡Ù… Ù‡Ø³ØªÙ†Ø¯.  \n",
    "  (Ø¯Ø± Ø¹Ù…Ù„ Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø±Ø³Øª Ù†ÛŒØ³ØªØŒ ÙˆÙ„ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ¨ Ø¬ÙˆØ§Ø¨ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯!)\n",
    "- Ø§ÛŒÙ† ÙØ±Ø¶ Ø³Ø§Ø¯Ù‡â€ŒØ§Ù†Ú¯Ø§Ø±Ø§Ù†Ù‡ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø³ÛŒØ§Ø± **Ø³Ø±ÛŒØ¹** Ùˆ **Ø³Ø¨Ú©** Ø¨Ø§Ø´Ø¯.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Naive Bayes\n",
    "\n",
    "- âœ… ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª (Sentiment Analysis)\n",
    "- âœ… ØªØ´Ø®ÛŒØµ Ø§Ø³Ù¾Ù… ÛŒØ§ Ø§ÛŒÙ…ÛŒÙ„ Ø³Ø§Ù„Ù…\n",
    "- âœ… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªÙˆÙ† (Ø§Ø®Ø¨Ø§Ø±ØŒ Ù†Ø¸Ø±Ø§ØªØŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§)\n",
    "- âœ… ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†\n",
    "- âœ… Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ÛŒØª Ù¾Ù†Ù‡Ø§Ù† ÛŒØ§ Ø§Ø­Ø³Ø§Ø³ ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ…\n",
    "- âœ… Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø³Ù†Ø§Ø¯ ÛŒØ§ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙØªØ§Ø±\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± ÛŒÚ© Ø¬Ù…Ù„Ù‡:\n",
    "\n",
    "> **Ø¨Ø§ÛŒØ² Ø³Ø§Ø¯Ù‡ØŒ Ø¨Ø§ ÙØ±Ø¶ Ù…Ø³ØªÙ‚Ù„ Ø¨ÙˆØ¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¨Ø§ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø³Ø±ÛŒØ¹ Ø§Ø­ØªÙ…Ø§Ù„ØŒ ÛŒÚ©ÛŒ Ø§Ø² Ú©Ø§Ø±Ø¢Ù…Ø¯ØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ø±ÛŒØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø³Øª.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡\n",
    "texts = [\n",
    "    \"Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ¨ Ø¨ÙˆØ¯\",               # Ù…Ø«Ø¨Øª\n",
    "    \"Ø§ÙØªØ¶Ø§Ø­ Ø¨ÙˆØ¯ØŒ Ø§ØµÙ„Ø§Ù‹ Ø¯ÙˆØ³Øª Ù†Ø¯Ø§Ø´ØªÙ…\", # Ù…Ù†ÙÛŒ\n",
    "    \"Ù†Ù‡ Ø¨Ø¯ Ø¨ÙˆØ¯ Ù†Ù‡ Ø®ÙˆØ¨\",           # Ø®Ù†Ø«ÛŒ\n",
    "    \"Ø¹Ø§Ø´Ù‚ Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø´Ø¯Ù…\",         # Ù…Ø«Ø¨Øª\n",
    "    \"Ù†Ù…ÛŒâ€ŒØ®Ø±Ù… Ø¯ÛŒÚ¯Ù‡\",               # Ù…Ù†ÙÛŒ\n",
    "    \"Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨ÙˆØ¯\",                 # Ø®Ù†Ø«ÛŒ\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=0)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÛŒÚ© Ø¬Ù…Ù„Ù‡â€ŒÛŒ Ù¾Ù†Ù‡Ø§Ù†â€ŒØ§Ø­Ø³Ø§Ø³\n",
    "sentence = [\"Ø¨Ø¯ Ù†Ø¨ÙˆØ¯ ÙˆÙ„ÛŒ Ø­Ø³ Ø®ÙˆØ¨ÛŒ Ù†Ø¯Ø§Ø´ØªÙ…\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "prediction = model.predict(vec)\n",
    "print(\"ğŸ” Ø§Ø­Ø³Ø§Ø³ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš¡ï¸ Gradient Boosting Machines (Ù…Ø§Ø´ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù† Ø¨ÙˆØ³ØªÛŒÙ†Ú¯)\n",
    "Ú¯Ø§Ù‡ÛŒ Ø¨Ù‡Ø´ Ù…ÛŒâ€ŒÚ¯Ù†: **GBM** ÛŒØ§ Â«Ø¨ÙˆØ³ØªÛŒÙ†Ú¯ ØªØ¯Ø±ÛŒØ¬ÛŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†Â»\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Ú†Ú¯ÙˆÙ†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ\n",
    "\n",
    "Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… **GBM** ÛŒÚ©ÛŒ Ø§Ø² Ù‚ÙˆÛŒâ€ŒØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ Ø¯Ø± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ (Classification) Ùˆ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† (Regression) Ø§Ø³Øª.\n",
    "\n",
    "- Ø§Ø¨ØªØ¯Ø§ ÛŒÚ© Ù…Ø¯Ù„ Ø¶Ø¹ÛŒÙ (Ù…Ø§Ù†Ù†Ø¯ ÛŒÚ© Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ú©ÙˆÚ†Ú©) Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
    "- Ù…Ø¯Ù„ Ø¯ÙˆÙ… Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ **Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ** Ø±Ø§ Ø§ØµÙ„Ø§Ø­ Ú©Ù†Ø¯.\n",
    "- Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡â€ŒØµÙˆØ±Øª ØªØ¯Ø±ÛŒØ¬ÛŒ Ùˆ ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒÛŒØ§Ø¨Ø¯Ø› Ù‡Ø± Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ **Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ** Ø±Ø§ Ø¬Ø¨Ø±Ø§Ù† Ú©Ù†Ø¯.\n",
    "- Ø¯Ø± Ù¾Ø§ÛŒØ§Ù†ØŒ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù‡Ù… ØªØ±Ú©ÛŒØ¨ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ ØªØ§ ÛŒÚ© **Ù…Ø¯Ù„ Ù‚ÙˆÛŒ Ùˆ Ø¯Ù‚ÛŒÙ‚** Ø¨Ø³Ø§Ø²Ù†Ø¯.\n",
    "\n",
    "ğŸŒ± **Ø¨ÙˆØ³ØªÛŒÙ†Ú¯** ÛŒØ¹Ù†ÛŒ ØªÙ‚ÙˆÛŒØª ØªØ¯Ø±ÛŒØ¬ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§.  \n",
    "ğŸ“‰ **Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†** ÛŒØ¹Ù†ÛŒ Ø­Ø±Ú©Øª Ø¨Ù‡ Ø³Ù…Øª Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø´ÛŒØ¨ (gradient) Ø®Ø·Ø§Ù‡Ø§.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù… GBM\n",
    "\n",
    "- **ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª (Sentiment Analysis):**  \n",
    "  ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…Ø«Ø¨ØªØŒ Ù…Ù†ÙÛŒ ÛŒØ§ Ø®Ù†Ø«ÛŒØŒ Ø­ØªÛŒ Ø¯Ø± Ø¬Ù…Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡ ÛŒØ§ Ú†Ù†Ø¯Ù…Ø¹Ù†Ø§ÛŒÛŒ âœ¨\n",
    "\n",
    "- **ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ø®ÙˆØ¯Ø¢Ú¯Ø§Ù‡ Ø¯Ø± Ù…ØªÙˆÙ†:**  \n",
    "  Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù„Ø­Ù† ÛŒØ§ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù¾Ù†Ù‡Ø§Ù† (Ù…Ø«Ù„Ø§Ù‹ Ø¬Ù…Ù„Ø§Øª Ø·Ø¹Ù†Ù‡â€ŒØ¢Ù…ÛŒØ² ÛŒØ§ ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ…) ğŸ˜Œ\n",
    "\n",
    "- **ØªØ´Ø®ÛŒØµ Ø§Ø³Ù¾Ù…:**  \n",
    "  Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ ÛŒØ§ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ù¾Ù…ØŒ Ø­ØªÛŒ Ø§Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø´Ø¨ÛŒÙ‡ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯.\n",
    "\n",
    "- **Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø¯Ù‡Ù†Ø¯Ù‡ (Recommendation Systems):**  \n",
    "  Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ÙÛŒÙ„Ù…ØŒ Ú©ØªØ§Ø¨ ÛŒØ§ Ù…Ø­ØµÙˆÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ùˆ ÙˆØ§Ú©Ù†Ø´ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†.\n",
    "\n",
    "- **Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙØªØ§Ø± Ú©Ø§Ø±Ø¨Ø±:**  \n",
    "  Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª ÛŒØ§ ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙØªØ§Ø±Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ ğŸ§ \n",
    "\n",
    "- **Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ø± Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ:**  \n",
    "  Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±ÙˆØ§Ø¨Ø· ØºÛŒØ±Ø®Ø·ÛŒ Ø¨ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª ÛŒØ§ Ø±ÛŒØ³Ú© ğŸ“‰ğŸ“ˆ\n",
    "\n",
    "- **Ù¾Ø²Ø´Ú©ÛŒ Ùˆ Ø³Ù„Ø§Ù…Øª Ø±ÙˆØ§Ù†:**  \n",
    "  ØªØ­Ù„ÛŒÙ„ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ØŒ Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±Ø§Ù† ÛŒØ§ ÛŒØ§Ø¯Ø¯Ø§Ø´Øªâ€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ§Ù†â€ŒØ´Ù†Ø§Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù¾Ù†Ù‡Ø§Ù† Ùˆ ØªØ´Ø®ÛŒØµ Ø²ÙˆØ¯Ù‡Ù†Ú¯Ø§Ù… Ø¨ÛŒÙ…Ø§Ø±ÛŒâ€ŒÙ‡Ø§.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± ÛŒÚ© Ø¬Ù…Ù„Ù‡:\n",
    "\n",
    "> **GBM Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¶Ø¹ÛŒÙ Ùˆ Ø§ØµÙ„Ø§Ø­ ØªØ¯Ø±ÛŒØ¬ÛŒ Ø®Ø·Ø§Ù‡Ø§ØŒ ÛŒÚ©ÛŒ Ø§Ø² Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ØªØ±ÛŒÙ† Ùˆ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø§Ø³Øª.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡\n",
    "texts = [\n",
    "    \"Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ´Ù… Ø§ÙˆÙ…Ø¯\",        # Ù…Ø«Ø¨Øª\n",
    "    \"Ø§ÙØªØ¶Ø§Ø­ Ø¨ÙˆØ¯\",             # Ù…Ù†ÙÛŒ\n",
    "    \"Ù†Ù‡ Ø®ÙˆØ¨ Ø¨ÙˆØ¯ Ù†Ù‡ Ø¨Ø¯\",      # Ø®Ù†Ø«ÛŒ\n",
    "    \"Ø¹Ø§Ø´Ù‚ Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø´Ø¯Ù…\",     # Ù…Ø«Ø¨Øª\n",
    "    \"ÙˆØ§Ù‚Ø¹Ø§ Ù¾Ø´ÛŒÙ…ÙˆÙ†Ù…\",          # Ù…Ù†ÙÛŒ\n",
    "    \"Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨ÙˆØ¯\",            # Ø®Ù†Ø«ÛŒ\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# Ø¨Ø±Ø¯Ø§Ø±Ø³Ø§Ø²ÛŒ Ù…ØªÙ†\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
    "y_pred = model.predict(X_test.toarray())\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÛŒÚ© Ø¬Ù…Ù„Ù‡â€ŒÛŒ Ø§Ø­Ø³Ø§Ø³â€ŒÙ¾Ù†Ù‡Ø§Ù†\n",
    "sentence = [\"Ù…Ø«Ù„Ø§Ù‹ Ú†ÛŒØ² Ø®ÙˆØ¨ÛŒ Ø¨ÙˆØ¯\"]\n",
    "vec = vectorizer.transform(sentence)\n",
    "prediction = model.predict(vec.toarray())\n",
    "print(\"ğŸ” Ø§Ø­Ø³Ø§Ø³ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¢ Logistic Regression (Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©)\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Ú†Ú¯ÙˆÙ†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ\n",
    "\n",
    "**Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©** Ø¨Ø±Ø®Ù„Ø§Ù Ø§Ø³Ù…Ø´ØŒ Ø¨Ø±Ø§ÛŒ **Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (Classification)** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ù†Ù‡ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø¹Ø¯Ø¯ÛŒ!  \n",
    "Ù‡Ø¯Ù Ø¢Ù† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ ØªØ¹Ù„Ù‚ ÛŒÚ© ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ù‡ ÛŒÚ© Ú©Ù„Ø§Ø³ Ø®Ø§Øµ Ø§Ø³ØªØŒ Ù…Ø«Ù„Ø§Ù‹:\n",
    "\n",
    "> Â«Ø§ÛŒÙ† Ø¬Ù…Ù„Ù‡ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Û¹Û°Ùª Ø§Ø­Ø³Ø§Ø³ Ù…Ø«Ø¨ØªÙ‡ Ùˆ Û±Û°Ùª Ù…Ù†ÙÛŒ.Â»\n",
    "\n",
    "- **ÙØ±Ù…ÙˆÙ„ Ø§ØµÙ„ÛŒ:**  \n",
    "  ØªØ§Ø¨Ø¹ Ø³ÛŒÚ¯Ù…ÙˆÛŒØ¯ (Sigmoid Function) Ú©Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø¨ÛŒÙ† Û° Ùˆ Û± Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯Ø› Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ù‡Ù…Ø§Ù† Ø§Ø­ØªÙ…Ø§Ù„ ØªØ¹Ù„Ù‚ Ø¨Ù‡ ÛŒÚ© Ú©Ù„Ø§Ø³ Ø®Ø§Øµ Ø§Ø³Øª.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù…\n",
    "\n",
    "- **ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª (Sentiment Analysis):**  \n",
    "  ØªØ´Ø®ÛŒØµ Ù…Ø«Ø¨Øª ÛŒØ§ Ù…Ù†ÙÛŒ Ø¨ÙˆØ¯Ù† Ù†Ø¸Ø±Ø§ØªØŒ ØªÙˆÛŒÛŒØªâ€ŒÙ‡Ø§ØŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ùˆ Ù†Ù‚Ø¯Ù‡Ø§.\n",
    "\n",
    "- **ØªØ´Ø®ÛŒØµ Ø§Ø³Ù¾Ù…:**  \n",
    "  Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³Ù¾Ù… Ø¨ÙˆØ¯Ù† Ø§ÛŒÙ…ÛŒÙ„â€ŒÙ‡Ø§ ÛŒØ§ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§.\n",
    "\n",
    "- **ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ø®ÙˆØ¯Ø¢Ú¯Ø§Ù‡ Ùˆ Ù„Ø­Ù†:**  \n",
    "  Ø­Ø¯Ø³ Ø²Ø¯Ù† Ø§Ø­Ø³Ø§Ø³ ÙˆØ§Ù‚Ø¹ÛŒ ÛŒØ§ Ù„Ø­Ù† Ù¾Ø´Øª ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù„Ù…Ø§Øª Ùˆ Ù†Ø­ÙˆÙ‡ Ø¨ÛŒØ§Ù†.\n",
    "\n",
    "- **ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø²Ø´Ú©ÛŒ:**  \n",
    "  Ù…Ø«Ù„Ø§Ù‹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ Ø§ÙØ³Ø±Ø¯Ú¯ÛŒ ÛŒØ§ Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø² Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ/Ø¹Ø¯Ø¯ÛŒ.\n",
    "\n",
    "- **Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø±Ø® Ø±ÛŒØ²Ø´ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† (Churn Prediction):**  \n",
    "  Ø¢ÛŒØ§ Ú©Ø§Ø±Ø¨Ø± Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† ÛŒØ§ Ø³Ø§ÛŒØª Ø±Ø§ ØªØ±Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ÛŒØ§ Ù†Ù‡ØŸ\n",
    "\n",
    "- **ØªØ´Ø®ÛŒØµ ØªÙ‚Ù„Ø¨ (Fraud Detection):**  \n",
    "  Ø³Ù†Ø¬Ø´ Ø§Ø­ØªÙ…Ø§Ù„ ØªÙ‚Ù„Ø¨ Ø¯Ø± ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù†Ú©ÛŒ ÛŒØ§ Ø®Ø±ÛŒØ¯Ù‡Ø§.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¬ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± ÛŒÚ© Ø¬Ù…Ù„Ù‡:\n",
    "\n",
    "> **Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ù„Ø¬Ø³ØªÛŒÚ©ØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ø³ÛŒÚ¯Ù…ÙˆÛŒØ¯ØŒ Ø§Ø­ØªÙ…Ø§Ù„ ØªØ¹Ù„Ù‚ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ù‡ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø±Ø§ ØªØ®Ù…ÛŒÙ† Ù…ÛŒâ€ŒØ²Ù†Ø¯ Ùˆ Ø¨Ù‡ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ\n",
    "texts = [\"I love this!\", \"This is bad\", \"What a great movie\", \"Horrible experience\"]\n",
    "labels = [1, 0, 1, 0]  # 1 = Ù…Ø«Ø¨ØªØŒ 0 = Ù…Ù†ÙÛŒ\n",
    "\n",
    "# ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
    "model = LogisticRegression()\n",
    "model.fit(X, labels)\n",
    "\n",
    "# ØªØ³Øª\n",
    "test_text = [\"I hate this movie\"]\n",
    "test_vec = vectorizer.transform(test_text)\n",
    "prediction = model.predict(test_vec)\n",
    "\n",
    "print(\"Prediction:\", \"Ù…Ø«Ø¨Øª\" if prediction[0] == 1 else \"Ù…Ù†ÙÛŒ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
